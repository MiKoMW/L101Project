{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "rS1KRgyJzRYZ",
    "outputId": "ee0395a9-efe3-4ec1-a770-5ecb4aa55813"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>bio_only</th>\n",
       "      <th>upos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@paulwalk</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token label bio_only  upos\n",
       "0  @paulwalk     O        O  NOUN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "wnuttrain = 'https://storage.googleapis.com/wnut-2017_ner-shared-task/wnut17train_clean_tagged.txt'\n",
    "train = pd.read_table(wnuttrain, header=None, names=['token', 'label', 'bio_only', 'upos'])  # don't drop the empty lines yet, they show up as NaN in the data frame\n",
    "train.head(n=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2j2ZkRxuqCok"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oTtvqwpNzgVR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "i7fjK0PJzVFS",
    "outputId": "3c8b507e-5e32-4f0b-ae95-4e997b7c4bdb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>bio_only</th>\n",
       "      <th>upos</th>\n",
       "      <th>token_indices</th>\n",
       "      <th>pos_indices</th>\n",
       "      <th>char_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@paulwalk</td>\n",
       "      <td>O</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[75, 9, 26, 50, 43, 24, 26, 43, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It</td>\n",
       "      <td>O</td>\n",
       "      <td>2.0</td>\n",
       "      <td>PRON</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[36, 67]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'s</td>\n",
       "      <td>O</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AUX</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[74, 69]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "      <td>2.0</td>\n",
       "      <td>DET</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[67, 31, 49]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>view</td>\n",
       "      <td>O</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[33, 32, 49, 24]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>from</td>\n",
       "      <td>O</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ADP</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[41, 90, 13, 72]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>where</td>\n",
       "      <td>O</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ADV</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[24, 31, 49, 90, 49]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I</td>\n",
       "      <td>O</td>\n",
       "      <td>2.0</td>\n",
       "      <td>PRON</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[36]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'m</td>\n",
       "      <td>O</td>\n",
       "      <td>2.0</td>\n",
       "      <td>X</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[74, 72]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>living</td>\n",
       "      <td>O</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[43, 32, 33, 32, 40, 35]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token label  bio_only  upos  token_indices  pos_indices  \\\n",
       "0  @paulwalk     O       2.0  NOUN            0.0          0.0   \n",
       "1         It     O       2.0  PRON            1.0          1.0   \n",
       "2         's     O       2.0   AUX            2.0          2.0   \n",
       "3        the     O       2.0   DET            3.0          3.0   \n",
       "4       view     O       2.0  NOUN            4.0          0.0   \n",
       "5       from     O       2.0   ADP            5.0          4.0   \n",
       "6      where     O       2.0   ADV            6.0          5.0   \n",
       "7          I     O       2.0  PRON            7.0          1.0   \n",
       "8         'm     O       2.0     X            8.0          6.0   \n",
       "9     living     O       2.0  NOUN            9.0          0.0   \n",
       "\n",
       "                            char_list  \n",
       "0  [75, 9, 26, 50, 43, 24, 26, 43, 2]  \n",
       "1                            [36, 67]  \n",
       "2                            [74, 69]  \n",
       "3                        [67, 31, 49]  \n",
       "4                    [33, 32, 49, 24]  \n",
       "5                    [41, 90, 13, 72]  \n",
       "6                [24, 31, 49, 90, 49]  \n",
       "7                                [36]  \n",
       "8                            [74, 72]  \n",
       "9            [43, 32, 33, 32, 40, 35]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Extraction\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "# in order to convert word tokens to integers: list the set of token types\n",
    "token_vocab = train.token.unique().tolist()\n",
    "oov = len(token_vocab)  # OOV (out of vocabulary) token as vocab length (because that's max.index + 1)\n",
    "\n",
    "\n",
    "# convert word tokens to integers\n",
    "def token_index(tok):\n",
    "  ind = tok\n",
    "  if not pd.isnull(tok):  # new since last time: deal with the empty lines which we didn't drop yet\n",
    "    if tok in token_vocab:  # if token in vocabulary\n",
    "      ind = token_vocab.index(tok)\n",
    "    else:  # else it's OOV\n",
    "      ind = oov\n",
    "  return ind\n",
    "\n",
    "\n",
    "#### DONE: Convert the POS Tag Into Integer.\n",
    "\n",
    "pos_vocab = train.upos.unique().tolist()\n",
    "oov_pos = len(pos_vocab)  # OOV (out of vocabulary) token as vocab length (because that's max.index + 1)\n",
    "# print(oov_pos)\n",
    "\n",
    "# Convert POS tag into Integers\n",
    "def pos_index(tok):\n",
    "  ind = tok\n",
    "  if not pd.isnull(tok):  # new since last time: deal with the empty lines which we didn't drop yet\n",
    "    if tok in pos_vocab:  # if token in vocabulary\n",
    "      ind = pos_vocab.index(tok)\n",
    "    else:  # else it's OOV\n",
    "      ind = oov_pos\n",
    "  return ind\n",
    "\n",
    "\n",
    "# training labels: convert BIO to integers\n",
    "def bio_index(bio):\n",
    "  ind = bio\n",
    "  if not pd.isnull(bio):  # deal with empty lines\n",
    "    if bio=='B':\n",
    "      ind = 0\n",
    "    elif bio=='I':\n",
    "      ind = 1\n",
    "    elif bio=='O':\n",
    "      ind = 2\n",
    "  return ind\n",
    "\n",
    "\n",
    "# Working Create Character Level Embedding\n",
    "\n",
    "\n",
    "# print(char_vocab)\n",
    "all_chars = set()\n",
    "for item in train.token:\n",
    "  if not (pd.isnull(item)):\n",
    "    for ch in item:\n",
    "      all_chars.add(ch)\n",
    "\n",
    "all_chars = list(all_chars)\n",
    "char_vocab = (all_chars)\n",
    "oov_char = len(char_vocab)\n",
    "\n",
    "\n",
    "# Convert Ch tag into Integers\n",
    "def char_index(word):\n",
    "  ans = []\n",
    "  if not pd.isnull(word):\n",
    "    for ch in word:\n",
    "      if ch in char_vocab:  # if token in vocabulary\n",
    "        ind = char_vocab.index(ch)\n",
    "      else:  # else it's OOV\n",
    "        ind = oov_char\n",
    "      ans.append(ind)\n",
    "    return ans\n",
    "  return []\n",
    "\n",
    "\n",
    "# pass a data frame through our feature extractor\n",
    "def extract_features(txt_orig,istest=False):\n",
    "  txt = txt_orig.copy()\n",
    "  tokinds = [token_index(u) for u in txt['token']]\n",
    "  txt['token_indices'] = tokinds\n",
    "\n",
    "\n",
    "  posinds = [pos_index(u) for u in txt['upos']]\n",
    "  txt['pos_indices'] = posinds\n",
    "\n",
    "  charsinds = [char_index(u) for u in txt['token']]\n",
    "\n",
    "  txt['char_list'] = charsinds\n",
    "\n",
    "\n",
    "  if not istest:  # can't do this with the test set\n",
    "    bioints = [bio_index(b) for b in txt['bio_only']]\n",
    "    txt['bio_only'] = bioints\n",
    "  return txt\n",
    "\n",
    "train_copy = extract_features(train)\n",
    "train_copy.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114
    },
    "id": "6Mz2z1O5zdp2",
    "outputId": "8c97e660-55dc-4994-b6a3-834add602fb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This cell takes a little while to run: be patient :)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_num</th>\n",
       "      <th>token</th>\n",
       "      <th>bio_only</th>\n",
       "      <th>token_indices</th>\n",
       "      <th>upos</th>\n",
       "      <th>pos_indices</th>\n",
       "      <th>char_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[@paulwalk, It, 's, the, view, from, where, I,...</td>\n",
       "      <td>[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>[NOUN, PRON, AUX, DET, NOUN, ADP, ADV, PRON, X...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 0.0, 4.0, 5.0, 1.0, 6.0, ...</td>\n",
       "      <td>[[75, 9, 26, 50, 43, 24, 26, 43, 2], [36, 67],...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_num                                              token  \\\n",
       "0             0  [@paulwalk, It, 's, the, view, from, where, I,...   \n",
       "\n",
       "                                            bio_only  \\\n",
       "0  [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...   \n",
       "\n",
       "                                       token_indices  \\\n",
       "0  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...   \n",
       "\n",
       "                                                upos  \\\n",
       "0  [NOUN, PRON, AUX, DET, NOUN, ADP, ADV, PRON, X...   \n",
       "\n",
       "                                         pos_indices  \\\n",
       "0  [0.0, 1.0, 2.0, 3.0, 0.0, 4.0, 5.0, 1.0, 6.0, ...   \n",
       "\n",
       "                                           char_list  \n",
       "0  [[75, 9, 26, 50, 43, 24, 26, 43, 2], [36, 67],...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokens2sequences(txt_orig,istest=False):\n",
    "  '''\n",
    "  Takes panda dataframe as input, copies, and adds a sequence index based on full-stops.\n",
    "  Outputs a dataframe with sequences of tokens, named entity labels, and token indices as lists.\n",
    "  '''\n",
    "  txt = txt_orig.copy()\n",
    "  txt['sequence_num'] = 0\n",
    "  seqcount = 0\n",
    "  for i in txt.index:  # in each row...\n",
    "    txt.loc[i,'sequence_num'] = seqcount  # set the sequence number\n",
    "    if pd.isnull(txt.loc[i,'token']):  # increment sequence counter at empty lines\n",
    "      seqcount += 1\n",
    "  # now drop the empty lines, group by sequence number and output df of sequence lists\n",
    "  txt = txt.dropna()\n",
    "  if istest:  # test set doesn't have labels\n",
    "    txt_seqs = txt.groupby(['sequence_num'],as_index=False)[['token', 'token_indices', \"upos\", \"pos_indices\",\"char_list\"]].agg(lambda x: list(x))\n",
    "  else:\n",
    "    txt_seqs = txt.groupby(['sequence_num'],as_index=False)[['token', 'bio_only', 'token_indices', 'upos', \"pos_indices\",\"char_list\"]].agg(lambda x: list(x))\n",
    "  return txt_seqs\n",
    "\n",
    "print(\"This cell takes a little while to run: be patient :)\")\n",
    "train_seqs = tokens2sequences(train_copy)\n",
    "train_seqs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "67XICD-Jz5j7",
    "outputId": "f17f1231-cdc2-4e3d-d914-3baebbf7021d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_num</th>\n",
       "      <th>token</th>\n",
       "      <th>bio_only</th>\n",
       "      <th>token_indices</th>\n",
       "      <th>upos</th>\n",
       "      <th>pos_indices</th>\n",
       "      <th>char_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@paulwalk</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0</td>\n",
       "      <td>[75, 9, 26, 50, 43, 24, 26, 43, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>It</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>PRON</td>\n",
       "      <td>1</td>\n",
       "      <td>[36, 67]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>'s</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>AUX</td>\n",
       "      <td>2</td>\n",
       "      <td>[74, 69]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>DET</td>\n",
       "      <td>3</td>\n",
       "      <td>[67, 31, 49]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>view</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0</td>\n",
       "      <td>[33, 32, 49, 24]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_num      token bio_only token_indices  upos pos_indices  \\\n",
       "0             0  @paulwalk        2             0  NOUN           0   \n",
       "1             0         It        2             1  PRON           1   \n",
       "2             0         's        2             2   AUX           2   \n",
       "3             0        the        2             3   DET           3   \n",
       "4             0       view        2             4  NOUN           0   \n",
       "\n",
       "                            char_list  \n",
       "0  [75, 9, 26, 50, 43, 24, 26, 43, 2]  \n",
       "1                            [36, 67]  \n",
       "2                            [74, 69]  \n",
       "3                        [67, 31, 49]  \n",
       "4                    [33, 32, 49, 24]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use sequence number as the index and apply pandas explode to all other columns\n",
    "train_back = train_seqs.set_index('sequence_num').apply(pd.Series.explode).reset_index()\n",
    "train_back.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yO5S8ChZBfTm",
    "outputId": "51b93ba8-987d-4aa3-d6f2-351ff21e1eda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest chars in the training set is 121 tokens long\n"
     ]
    }
   ],
   "source": [
    "def find_longest_chars(txt,longest_seq):\n",
    "  '''find the longest sequence in the dataframe'''\n",
    "  for i in txt.index:\n",
    "    seqlen = np.max(list(map(lambda x : len(x), (txt['char_list'][i]))))\n",
    "    if seqlen > longest_seq:  # update high water mark if new longest sequence encountered\n",
    "      longest_seq = seqlen\n",
    "  return longest_seq\n",
    "\n",
    "\n",
    "train_longest_char = find_longest_chars(train_seqs,0)\n",
    "print('The longest chars in the training set is %i tokens long' % train_longest_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kLrK7NyRz59_",
    "outputId": "7b025a58-b718-47e9-8b57-066de61e4b0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest sequence in the training set is 41 tokens long\n"
     ]
    }
   ],
   "source": [
    "def find_longest_sequence(txt,longest_seq):\n",
    "  '''find the longest sequence in the dataframe'''\n",
    "  for i in txt.index:\n",
    "    seqlen = len(txt['token'][i])\n",
    "    if seqlen > longest_seq:  # update high water mark if new longest sequence encountered\n",
    "      longest_seq = seqlen\n",
    "  return longest_seq\n",
    "\n",
    "train_longest = find_longest_sequence(train_seqs,0)\n",
    "print('The longest sequence in the training set is %i tokens long' % train_longest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pEqW_vMBz6Bp",
    "outputId": "a5954dd4-2c78-4c82-a1af-a27917caca01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest sequence in the dev set is 82 tokens long\n",
      "The longest char in the dev set is 66 tokens long\n",
      "The longest sequence in the test set is 105 tokens long\n",
      "The longest char in the test set is 195 tokens long\n"
     ]
    }
   ],
   "source": [
    "# the dev set\n",
    "wnutdev = 'https://storage.googleapis.com/wnut-2017_ner-shared-task/wnut17dev_clean_tagged.txt'\n",
    "dev = pd.read_table(wnutdev, header=None, names=['token', 'label', 'bio_only', 'upos'])\n",
    "dev_copy = extract_features(dev)\n",
    "dev_seqs = tokens2sequences(dev_copy)\n",
    "dev_longest = find_longest_sequence(dev_seqs,0)\n",
    "print('The longest sequence in the dev set is %i tokens long' % dev_longest)\n",
    "\n",
    "dev_longest_char = find_longest_chars(dev_seqs,0)\n",
    "print('The longest char in the dev set is %i tokens long' % dev_longest_char)\n",
    "\n",
    "# the test set\n",
    "wnuttest = 'https://storage.googleapis.com/wnut-2017_ner-shared-task/wnut17test_clean_tagged.txt'\n",
    "test = pd.read_table(wnuttest, header=None, names=['token', 'upos'])\n",
    "test_copy = extract_features(test, True)\n",
    "test_seqs = tokens2sequences(test_copy, True)\n",
    "test_longest = find_longest_sequence(test_seqs,0)\n",
    "print('The longest sequence in the test set is %i tokens long' % test_longest)\n",
    "test_longest_char = find_longest_chars(test_seqs,0)\n",
    "print('The longest char in the test set is %i tokens long' % test_longest_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7eoJU9UeMT9q"
   },
   "outputs": [],
   "source": [
    "# def padd_char(seq):\n",
    "#   X_char = []\n",
    "#   for item in seq[\"char_list\"]:\n",
    "#      sent_seq = []\n",
    "#      for i in range(seq_length):\n",
    "#           word_seq = []\n",
    "#           for j in range(char_seq_length):\n",
    "#               try:\n",
    "#                   word_seq.append(item[j])\n",
    "#               except:\n",
    "#                   word_seq.append(char_padtok)\n",
    "#           sent_seq.append(word_seq)\n",
    "#      X_char.append(np.array(sent_seq))\n",
    "#   return X_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "FDxSd2zaMs7j"
   },
   "outputs": [],
   "source": [
    "def padd_char(seq):\n",
    "  temp_char_seqs_padded = []\n",
    "  for item in seq[\"char_list\"]:\n",
    "    temp_pad = pad_sequences(item, maxlen=char_seq_length,\n",
    "                                  dtype='int32', padding='post', truncating='post', value=char_padtok)\n",
    "  \n",
    "    a = temp_pad\n",
    "    b = [[char_padtok for i in range(char_seq_length)] for _ in range(0, seq_length - len(temp_pad))]\n",
    "    c = np.concatenate((a, b))\n",
    "    # print(len(c))\n",
    "    temp_char_seqs_padded.append(c)\n",
    "  # print(len(temp_char_seqs_padded))\n",
    "  return temp_char_seqs_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "soufxysdz6E7",
    "outputId": "b568ae5f-7edd-4691-d677-995b0cbfc2b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The padding token index is 14802\n",
      "Example of padded token sequence:\n",
      "[   26    27    28    29    30    31    32    10    33    34    35    36\n",
      "    13    37    38 14802 14802 14802 14802 14802 14802 14802 14802 14802\n",
      " 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802\n",
      " 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802\n",
      " 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802\n",
      " 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802\n",
      " 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802\n",
      " 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802\n",
      " 14802 14802 14802 14802 14802 14802 14802 14802 14802]\n",
      "Example of padded pos sequence:\n",
      "[ 4  9  9  8  9  0  0  4  9  9  4  9  8  6  6 19 19 19 19 19 19 19 19 19\n",
      " 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19\n",
      " 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19\n",
      " 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19\n",
      " 19 19 19 19 19 19 19 19 19]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# set maximum sequence length\n",
    "seq_length = test_longest\n",
    "# char_seq_length = test_longest_char\n",
    "char_seq_length = 5\n",
    "\n",
    "# a new dummy token index, one more than OOV\n",
    "padtok = oov+1\n",
    "pos_padtok = oov_pos+1\n",
    "char_padtok = oov_char + 1\n",
    "\n",
    "print('The padding token index is %i' % padtok)\n",
    "\n",
    "# use pad_sequences, padding or truncating at the end of the sequence (default is 'pre')\n",
    "train_seqs_padded = pad_sequences(train_seqs['token_indices'].tolist(), maxlen=seq_length,\n",
    "                                  dtype='int32', padding='post', truncating='post', value=padtok)\n",
    "\n",
    "\n",
    "\n",
    "train_pos_seqs_padded = pad_sequences(train_seqs['pos_indices'].tolist(), maxlen=seq_length,\n",
    "                                  dtype='int32', padding='post', truncating='post', value=pos_padtok)\n",
    "\n",
    "\n",
    "\n",
    "# Pad Character Level \n",
    "train_char_seqs_padded = padd_char(train_seqs)\n",
    "\n",
    "# for item in train_seqs[\"char_list\"]:\n",
    "#   temp_pad = pad_sequences(item, maxlen=char_seq_length,\n",
    "#                                   dtype='int32', padding='post', truncating='post', value=char_padtok)\n",
    "  \n",
    "#   a = temp_pad\n",
    "#   b = [[char_padtok for i in range(char_seq_length)] for _ in range(0, seq_length - len(temp_pad))]\n",
    "#   c = np.concatenate((a, b))\n",
    "#   # print(len(c))\n",
    "#   train_char_seqs_padded.append(c)\n",
    "\n",
    "print('Example of padded token sequence:')\n",
    "print(train_seqs_padded[1])\n",
    "\n",
    "\n",
    "print('Example of padded pos sequence:')\n",
    "print(train_pos_seqs_padded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "dWVF31ooNGol"
   },
   "outputs": [],
   "source": [
    "assert len(train_char_seqs_padded) == len(train_seqs_padded)\n",
    "for item in train_char_seqs_padded:\n",
    "  assert len(item) == len(train_seqs_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U1Vt4R-Gz6Ho",
    "outputId": "a9898038-abb1-4c1b-b519-3e8e2201183b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of padded label sequence and one-hot encoding (first 10 tokens):\n",
      "sequence_num                                                     1\n",
      "token            [From, Green, Newsfeed, :, AHFA, extends, dead...\n",
      "bio_only         [2.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0, 2.0, 2.0, ...\n",
      "token_indices    [26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 10....\n",
      "upos             [ADP, PROPN, PROPN, PUNCT, PROPN, NOUN, NOUN, ...\n",
      "pos_indices      [4.0, 9.0, 9.0, 8.0, 9.0, 0.0, 0.0, 4.0, 9.0, ...\n",
      "char_list        [[8, 90, 13, 72], [12, 90, 49, 49, 40], [19, 4...\n",
      "Name: 1, dtype: object\n",
      "Length of input sequence: 105\n",
      "Length of label sequence: 105\n",
      "[2 2 2 2 0 2 2 2 2 2 2]\n",
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# get lists of named entity labels, padded with a null label (=3)\n",
    "padlab = 3\n",
    "train_labs_padded = pad_sequences(train_seqs['bio_only'].tolist(), maxlen=seq_length,\n",
    "                                  dtype='int32', padding='post', truncating='post', value=padlab)\n",
    "\n",
    "# convert those labels to one-hot encoding\n",
    "n_labs = 4  # we have 3 labels: B, I, O (0, 1, 2) + the pad label 3\n",
    "train_labs_onehot = [to_categorical(i, num_classes=n_labs) for i in train_labs_padded]\n",
    "\n",
    "# follow the print outputs below to see how the labels are transformed\n",
    "print('Example of padded label sequence and one-hot encoding (first 10 tokens):')\n",
    "print(train_seqs.loc[1])\n",
    "print('Length of input sequence: %i' % len(train_labs_padded[1]))\n",
    "print('Length of label sequence: %i' % len(train_labs_onehot[1]))\n",
    "print(train_labs_padded[1][:11])\n",
    "print(train_labs_onehot[1][:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7vol4FFhz6Kb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S6yrwKjuz6M-",
    "outputId": "540ead20-7093-4274-cedd-57847fcdd767"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev set padded label sequence and one-hot encoding (first 10 tokens):\n",
      "sequence_num                                                     2\n",
      "token            [All, I, ', ve, been, doing, is, BINGE, watchi...\n",
      "bio_only         [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...\n",
      "token_indices    [405.0, 7.0, 573.0, 12927.0, 90.0, 848.0, 52.0...\n",
      "upos             [DET, PRON, PUNCT, NOUN, AUX, VERB, AUX, PROPN...\n",
      "pos_indices      [3.0, 1.0, 8.0, 0.0, 2.0, 14.0, 2.0, 9.0, 14.0...\n",
      "char_list        [[21, 43, 43], [36], [74], [33, 49], [22, 49, ...\n",
      "Name: 2, dtype: object\n",
      "Length of input sequence: 105\n",
      "Length of label sequence: 105\n",
      "[2 2 2 2 2 2 2 2 2 0 1]\n",
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Prepare Dev Set\n",
    "# now process the dev set in the same way: padding the tokens & labels, and one-hot encoding the labels\n",
    "dev_seqs_padded = pad_sequences(dev_seqs['token_indices'].tolist(), maxlen=seq_length,\n",
    "                                dtype='int32', padding='post', truncating='post', value=padtok)\n",
    "dev_labs_padded = pad_sequences(dev_seqs['bio_only'].tolist(), maxlen=seq_length,\n",
    "                                dtype='int32', padding='post', truncating='post', value=padlab)\n",
    "dev_labs_onehot = [to_categorical(i, num_classes=n_labs) for i in dev_labs_padded]\n",
    "\n",
    "dev_pos_seqs_padded = pad_sequences(dev_seqs['pos_indices'].tolist(), maxlen=seq_length,\n",
    "                                  dtype='int32', padding='post', truncating='post', value=pos_padtok)\n",
    "\n",
    "dev_char_seqs_padded = padd_char(dev_seqs)\n",
    "\n",
    "\n",
    "print('Dev set padded label sequence and one-hot encoding (first 10 tokens):')\n",
    "print(dev_seqs.loc[2])\n",
    "print('Length of input sequence: %i' % len(dev_labs_padded[1]))\n",
    "print('Length of label sequence: %i' % len(dev_labs_onehot[1]))\n",
    "print(dev_labs_padded[2][:11])\n",
    "print(dev_labs_onehot[2][:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "b0FzHDB_z6Pl"
   },
   "outputs": [],
   "source": [
    "assert len(dev_char_seqs_padded) == len(dev_pos_seqs_padded)\n",
    "for item in dev_char_seqs_padded:\n",
    "  assert len(item) == len(dev_pos_seqs_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ij2J13sI6035",
    "outputId": "9dbcc0c6-b2f3-466a-f0fd-9f9c42677209"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence dimensions (n.docs, seq.length):\n",
      "(3375, 105)\n",
      "Input pos dimensions (n.docs, seq.length):\n",
      "(3375, 105)\n",
      "Input char dimensions (n.docs, seq.length):\n",
      "(3375, 105, 5)\n",
      "Label dimensions (n.docs, seq.length, one-hot encoding of 4 NER labels):\n",
      "(3375, 105, 4)\n",
      "**Defining a neural network**\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input3 (InputLayer)        [(None, 105, 5)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tok_input1 (InputLayer)         [(None, 105)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pos_input2 (InputLayer)         [(None, 105)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 105, 5, 128)  12032       char_input3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 105, 128)     1894784     tok_input1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 105, 128)     2560        pos_input2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 105, 100)     71600       time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 105, 356)     0           embedding_1[0][0]                \n",
      "                                                                 embedding_2[0][0]                \n",
      "                                                                 time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 105, 100)     162800      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 105, 100)     0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 105, 4)       404         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,144,180\n",
      "Trainable params: 2,144,180\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load Keras and TensorFlow\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "# from keras_contrib.layers import CRF\n",
    "\n",
    "# prepare sequences and labels as numpy arrays, check dimensions\n",
    "X = np.array(train_seqs_padded)\n",
    "y = np.array(train_labs_onehot)\n",
    "X_pos = np.array(train_pos_seqs_padded)\n",
    "X_char = np.array(train_char_seqs_padded)\n",
    "\n",
    "print('Input sequence dimensions (n.docs, seq.length):')\n",
    "print(X.shape)\n",
    "print('Input pos dimensions (n.docs, seq.length):')\n",
    "print(X_pos.shape)\n",
    "print('Input char dimensions (n.docs, seq.length):')\n",
    "print(X_char.shape)\n",
    "print('Label dimensions (n.docs, seq.length, one-hot encoding of 4 NER labels):')\n",
    "print(y.shape)\n",
    "\n",
    "# our final vocab size is the padding token + 1 (OR length of vocab + OOV + PAD)\n",
    "vocab_size = padtok+1\n",
    "assert (vocab_size==len(token_vocab)+2)\n",
    "\n",
    "\n",
    "# Validate the index of pos tag.\n",
    "\n",
    "pos_size = pos_padtok + 1\n",
    "assert (pos_size==len(pos_vocab)+2)\n",
    "\n",
    "char_size = char_padtok + 1\n",
    "assert (char_size==len(char_vocab)+2)\n",
    "\n",
    "embed_size = 128  # try an embedding size of 128 (could tune this)\n",
    "\n",
    "#Â list of metrics to use: true & false positives, negatives, accuracy, precision, recall, area under the curve\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "# our model has the option for an label prediction bias, it's sequential, starts with an embedding layer, then bi-LSTM,\n",
    "# a dropout layer follows for regularisation, and a dense final layer with softmax activation to output class probabilities\n",
    "# we compile with the Adam optimizer at a low learning rate, use categorical cross-entropy as our loss function\n",
    "def make_model(metrics = METRICS, output_bias=None):\n",
    "  if output_bias is not None:\n",
    "    output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "\n",
    "  tok_input1 = keras.layers.Input(shape=(seq_length,), dtype='int32', name='tok_input1')\n",
    "  pos_input2 = keras.layers.Input(shape=(seq_length,), dtype='int32', name='pos_input2')\n",
    "  # (\"CHAR INPUT\")\n",
    "  # print(char_input3)\n",
    "\n",
    "  # Character Level Model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # char_in = keras.layers.Input(shape=(seq_length,char_seq_length,), dtype='int32', name='char_in')\n",
    "  char_input3 = keras.layers.Input(shape=(seq_length,char_seq_length), dtype='int32', name='char_input3')\n",
    "  emb_char = keras.layers.TimeDistributed(keras.layers.Embedding(output_dim=embed_size, input_dim=char_size, input_length=5,  mask_zero=True, trainable=True))(char_input3)\n",
    "  char_enc = keras.layers.TimeDistributed(keras.layers.Bidirectional(keras.layers.LSTM(units=50, return_sequences=False, dropout=0.2, recurrent_dropout=0.2)))(emb_char)\n",
    "\n",
    "\n",
    "\n",
    "  # char_output = char_x_lstm\n",
    "  # char_model = tf.keras.Model(inputs=char_in, outputs=char_output)\n",
    "\n",
    "# input_inner = Input(shape=(4,), name='input_inner')\n",
    "# output_inner = Dense(3, name='inner_dense')(input_inner)\n",
    "# inner_model = Model(inputs=input_inner, outputs=output_inner)\n",
    "\n",
    "\n",
    "  # x3 = char_model(char_input3)\n",
    "\n",
    "  x1 = keras.layers.Embedding(output_dim=embed_size, input_dim=vocab_size,  input_length=seq_length,  mask_zero=True, trainable=True)(tok_input1)\n",
    "  x2 = keras.layers.Embedding(output_dim=embed_size, input_dim=pos_size,  input_length=seq_length, mask_zero=True, trainable=True)(pos_input2)\n",
    "  \n",
    "  # print(\":D\")\n",
    "  # print(tok_input1)\n",
    "  \n",
    "\n",
    "  x_cancat = keras.layers.concatenate([x1, x2, char_enc ])\n",
    "  # x_cancat = keras.layers.concatenate([x1, x2])\n",
    "\n",
    "  x_lstm = keras.layers.Bidirectional(keras.layers.LSTM(units=50, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))(x_cancat)\n",
    "  x_drop = keras.layers.Dropout(0.5)(x_lstm)\n",
    "  main_output = keras.layers.TimeDistributed(keras.layers.Dense(n_labs, activation='softmax', bias_initializer=output_bias))(x_drop)\n",
    " # model = keras.Sequential()\n",
    " # model.add(keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_size, input_length=seq_length, mask_zero=True, trainable=True))\n",
    "# model.add(keras.layers.Bidirectional(keras.layers.LSTM(units=50, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)))\n",
    "#  model.add(keras.layers.Dropout(0.5))\n",
    "#  model.add(keras.layers.TimeDistributed(keras.layers.Dense(n_labs, activation='softmax', bias_initializer=output_bias)))\n",
    "  # crf = CRF(4)  # CRF layer, n_tags+1(PAD)\n",
    "  # main_output = crf(main_output)  # output\n",
    "\n",
    "  model = keras.models.Model(inputs=[tok_input1, pos_input2, char_input3], outputs= main_output)\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(lr=1e-3), loss=keras.losses.CategoricalCrossentropy(), metrics=metrics)\n",
    "  return model\n",
    "\n",
    "# early stopping criteria based on area under the curve: will stop if no improvement after 10 epochs\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_auc', verbose=1, patience=10, mode='max', restore_best_weights=True)\n",
    "\n",
    "# the number of training epochs we'll use, and the batch size (how many texts are input at once)\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print('**Defining a neural network**')\n",
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ib8KD0EuMOBQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6J7R-P4560oT",
    "outputId": "63529675-902f-42e7-dbc5-840f6d602786"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.4288\n"
     ]
    }
   ],
   "source": [
    "# evaluate our initial model\n",
    "\n",
    "\n",
    "results = model.evaluate([X,X_pos,X_char], y, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dyY9ldZP-Ocm",
    "outputId": "6413a628-f2d0-444a-c17c-f9b7cc744ce9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 292139, 2: 59095, 0: 1964, 1: 1177})\n",
      "354375\n",
      "Initial bias:\n",
      "[0.005542151675485009, 0.0033213403880070548, 0.1667583774250441, 0.8243781305114638]\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Loss: 0.9316\n"
     ]
    }
   ],
   "source": [
    "# figure out the label distribution in our fixed-length texts\n",
    "from collections import Counter\n",
    "\n",
    "all_labs = [l for lab in train_labs_padded for l in lab]\n",
    "label_count = Counter(all_labs)\n",
    "total_labs = len(all_labs)\n",
    "print(label_count)\n",
    "print(total_labs)\n",
    "\n",
    "# use this to define an initial model bias\n",
    "initial_bias=[(label_count[0]/total_labs), (label_count[1]/total_labs),\n",
    "              (label_count[2]/total_labs), (label_count[3]/total_labs)]\n",
    "print('Initial bias:')\n",
    "print(initial_bias)\n",
    "\n",
    "# pass the bias to the model and re-evaluate\n",
    "model = make_model(output_bias=initial_bias)\n",
    "results = model.evaluate([X,X_pos,X_char], y, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "oHhUQoif60Tt"
   },
   "outputs": [],
   "source": [
    "# # prepare the dev sequences and labels as numpy arrays\n",
    "dev_X = np.array(dev_seqs_padded)\n",
    "dev_X_pos = np.array(dev_pos_seqs_padded)\n",
    "dev_X_char = np.array(dev_char_seqs_padded)\n",
    "dev_y = np.array(dev_labs_onehot)\n",
    "\n",
    "\n",
    "# # re-initiate model with bias\n",
    "# model = make_model(output_bias=initial_bias)\n",
    "\n",
    "# # and fit...\n",
    "# model.fit([X,X_pos] , y, batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks = [early_stopping], validation_data=([dev_X, dev_X_pos],dev_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "VHkx8CI360HW"
   },
   "outputs": [],
   "source": [
    "# # use argmax to figure out the class with highest probability per token\n",
    "# preds = np.argmax(model.predict([dev_seqs_padded,dev_pos_seqs_padded]), axis=-1)\n",
    "# flat_preds = [p for pred in preds for p in pred]\n",
    "# print(Counter(flat_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sEaH3IMk6zlo",
    "outputId": "afc129d7-36dc-4096-bd79-a310d29f5614"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial one-hot label encoding:\n",
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Weighted label encoding:\n",
      "[[0.  0.  0.1 0. ]\n",
      " [0.  0.  0.1 0. ]\n",
      " [0.  0.  0.1 0. ]\n",
      " [0.  0.  0.1 0. ]\n",
      " [1.  0.  0.  0. ]\n",
      " [0.  0.  0.1 0. ]\n",
      " [0.  0.  0.1 0. ]\n",
      " [0.  0.  0.1 0. ]\n",
      " [0.  0.  0.1 0. ]\n",
      " [0.  0.  0.1 0. ]\n",
      " [0.  0.  0.1 0. ]]\n"
     ]
    }
   ],
   "source": [
    "# use deep copy to ensure we aren't updating original values\n",
    "import copy\n",
    "train_weights_onehot = copy.deepcopy(train_labs_onehot)\n",
    "\n",
    "# our first-pass class weights: normal for named entities (0 and 1), down-weighted for non named entities (2 and 3)\n",
    "class_wts = [1,1,.1,.1]\n",
    "\n",
    "# apply our weights to the label lists\n",
    "for i,labs in enumerate(train_weights_onehot):\n",
    "  for j,lablist in enumerate(labs):\n",
    "    lablistaslist = lablist.tolist()\n",
    "    whichismax = lablistaslist.index(max(lablistaslist))\n",
    "    train_weights_onehot[i][j][whichismax] = class_wts[whichismax]\n",
    "\n",
    "# what's this like, before and after?\n",
    "print('Initial one-hot label encoding:')\n",
    "print(train_labs_onehot[1][:11])\n",
    "\n",
    "print('Weighted label encoding:')\n",
    "print(train_weights_onehot[1][:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XOzIYPR0Bow9",
    "outputId": "6d0cca9e-efba-4a09-ae69-6beb59c2dc2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label dimensions (n.docs, seq.length, one-hot encoding of 4 NER labels):\n",
      "(3375, 105, 4)\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "106/106 [==============================] - 49s 464ms/step - loss: 0.0246 - tp: 315685.0000 - fp: 5485.0000 - tn: 3183890.0000 - fn: 747440.0000 - accuracy: 0.7487 - precision: 0.9829 - recall: 0.2969 - auc: 0.9015 - val_loss: 0.0298 - val_tp: 100393.0000 - val_fp: 561.0000 - val_tn: 312234.0000 - val_fn: 3872.0000 - val_accuracy: 0.9894 - val_precision: 0.9944 - val_recall: 0.9629 - val_auc: 0.9993\n",
      "Epoch 2/100\n",
      "106/106 [==============================] - 47s 447ms/step - loss: 0.0106 - tp: 336382.0000 - fp: 2872.0000 - tn: 1060253.0000 - fn: 17993.0000 - accuracy: 0.7488 - precision: 0.9915 - recall: 0.9492 - auc: 0.9987 - val_loss: 0.0255 - val_tp: 100559.0000 - val_fp: 562.0000 - val_tn: 312233.0000 - val_fn: 3706.0000 - val_accuracy: 0.9898 - val_precision: 0.9944 - val_recall: 0.9645 - val_auc: 0.9993\n",
      "Epoch 3/100\n",
      "106/106 [==============================] - 59s 560ms/step - loss: 0.0075 - tp: 338325.0000 - fp: 2439.0000 - tn: 1060686.0000 - fn: 16050.0000 - accuracy: 0.7495 - precision: 0.9928 - recall: 0.9547 - auc: 0.9990 - val_loss: 0.0226 - val_tp: 100616.0000 - val_fp: 620.0000 - val_tn: 312175.0000 - val_fn: 3649.0000 - val_accuracy: 0.9898 - val_precision: 0.9939 - val_recall: 0.9650 - val_auc: 0.9993\n",
      "Epoch 4/100\n",
      "106/106 [==============================] - 43s 406ms/step - loss: 0.0046 - tp: 340064.0000 - fp: 1455.0000 - tn: 1061670.0000 - fn: 14311.0000 - accuracy: 0.7505 - precision: 0.9957 - recall: 0.9596 - auc: 0.9993 - val_loss: 0.0212 - val_tp: 100708.0000 - val_fp: 634.0000 - val_tn: 312161.0000 - val_fn: 3557.0000 - val_accuracy: 0.9900 - val_precision: 0.9937 - val_recall: 0.9659 - val_auc: 0.9992\n",
      "Epoch 5/100\n",
      "106/106 [==============================] - 42s 393ms/step - loss: 0.0029 - tp: 340927.0000 - fp: 967.0000 - tn: 1062158.0000 - fn: 13448.0000 - accuracy: 0.7510 - precision: 0.9972 - recall: 0.9621 - auc: 0.9994 - val_loss: 0.0234 - val_tp: 100692.0000 - val_fp: 708.0000 - val_tn: 312087.0000 - val_fn: 3573.0000 - val_accuracy: 0.9897 - val_precision: 0.9930 - val_recall: 0.9657 - val_auc: 0.9991\n",
      "Epoch 6/100\n",
      "106/106 [==============================] - 41s 387ms/step - loss: 0.0020 - tp: 341241.0000 - fp: 783.0000 - tn: 1062342.0000 - fn: 13134.0000 - accuracy: 0.7512 - precision: 0.9977 - recall: 0.9629 - auc: 0.9994 - val_loss: 0.0242 - val_tp: 100701.0000 - val_fp: 711.0000 - val_tn: 312084.0000 - val_fn: 3564.0000 - val_accuracy: 0.9897 - val_precision: 0.9930 - val_recall: 0.9658 - val_auc: 0.9990\n",
      "Epoch 7/100\n",
      "106/106 [==============================] - 41s 386ms/step - loss: 0.0015 - tp: 341359.0000 - fp: 714.0000 - tn: 1062411.0000 - fn: 13016.0000 - accuracy: 0.7513 - precision: 0.9979 - recall: 0.9633 - auc: 0.9994 - val_loss: 0.0247 - val_tp: 100740.0000 - val_fp: 708.0000 - val_tn: 312087.0000 - val_fn: 3525.0000 - val_accuracy: 0.9899 - val_precision: 0.9930 - val_recall: 0.9662 - val_auc: 0.9988\n",
      "Epoch 8/100\n",
      "106/106 [==============================] - 41s 388ms/step - loss: 0.0012 - tp: 341575.0000 - fp: 530.0000 - tn: 1062595.0000 - fn: 12800.0000 - accuracy: 0.7514 - precision: 0.9985 - recall: 0.9639 - auc: 0.9995 - val_loss: 0.0262 - val_tp: 100737.0000 - val_fp: 710.0000 - val_tn: 312085.0000 - val_fn: 3528.0000 - val_accuracy: 0.9898 - val_precision: 0.9930 - val_recall: 0.9662 - val_auc: 0.9987\n",
      "Epoch 9/100\n",
      "106/106 [==============================] - 41s 388ms/step - loss: 8.5741e-04 - tp: 341728.0000 - fp: 415.0000 - tn: 1062710.0000 - fn: 12647.0000 - accuracy: 0.7515 - precision: 0.9988 - recall: 0.9643 - auc: 0.9995 - val_loss: 0.0283 - val_tp: 100678.0000 - val_fp: 765.0000 - val_tn: 312030.0000 - val_fn: 3587.0000 - val_accuracy: 0.9896 - val_precision: 0.9925 - val_recall: 0.9656 - val_auc: 0.9986\n",
      "Epoch 10/100\n",
      "106/106 [==============================] - 41s 389ms/step - loss: 7.7156e-04 - tp: 341782.0000 - fp: 379.0000 - tn: 1062746.0000 - fn: 12593.0000 - accuracy: 0.7516 - precision: 0.9989 - recall: 0.9645 - auc: 0.9995 - val_loss: 0.0289 - val_tp: 100702.0000 - val_fp: 763.0000 - val_tn: 312032.0000 - val_fn: 3563.0000 - val_accuracy: 0.9896 - val_precision: 0.9925 - val_recall: 0.9658 - val_auc: 0.9985\n",
      "Epoch 11/100\n",
      "106/106 [==============================] - 41s 388ms/step - loss: 6.5770e-04 - tp: 341810.0000 - fp: 349.0000 - tn: 1062776.0000 - fn: 12565.0000 - accuracy: 0.7516 - precision: 0.9990 - recall: 0.9645 - auc: 0.9995 - val_loss: 0.0290 - val_tp: 100797.0000 - val_fp: 690.0000 - val_tn: 312105.0000 - val_fn: 3468.0000 - val_accuracy: 0.9900 - val_precision: 0.9932 - val_recall: 0.9667 - val_auc: 0.9984\n",
      "Epoch 12/100\n",
      "106/106 [==============================] - 41s 388ms/step - loss: 5.8922e-04 - tp: 341859.0000 - fp: 310.0000 - tn: 1062815.0000 - fn: 12516.0000 - accuracy: 0.7516 - precision: 0.9991 - recall: 0.9647 - auc: 0.9995 - val_loss: 0.0306 - val_tp: 100726.0000 - val_fp: 742.0000 - val_tn: 312053.0000 - val_fn: 3539.0000 - val_accuracy: 0.9897 - val_precision: 0.9927 - val_recall: 0.9661 - val_auc: 0.9983\n",
      "Epoch 13/100\n",
      "106/106 [==============================] - ETA: 0s - loss: 5.2827e-04 - tp: 341898.0000 - fp: 275.0000 - tn: 1062850.0000 - fn: 12477.0000 - accuracy: 0.7516 - precision: 0.9992 - recall: 0.9648 - auc: 0.9995Restoring model weights from the end of the best epoch.\n",
      "106/106 [==============================] - 41s 388ms/step - loss: 5.2827e-04 - tp: 341898.0000 - fp: 275.0000 - tn: 1062850.0000 - fn: 12477.0000 - accuracy: 0.7516 - precision: 0.9992 - recall: 0.9648 - auc: 0.9995 - val_loss: 0.0304 - val_tp: 100811.0000 - val_fp: 681.0000 - val_tn: 312114.0000 - val_fn: 3454.0000 - val_accuracy: 0.9901 - val_precision: 0.9933 - val_recall: 0.9669 - val_auc: 0.9983\n",
      "Epoch 00013: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f65201f9ac8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAINTRAIN\n",
    "# now try the weighted one-hot encoding\n",
    "y = np.array(train_weights_onehot)\n",
    "print('Label dimensions (n.docs, seq.length, one-hot encoding of 4 NER labels):')\n",
    "print(np.shape(y))\n",
    "\n",
    "\n",
    "\n",
    "model2 = make_model(output_bias=initial_bias)\n",
    "model2.fit([X,X_pos,X_char], y, batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks = [early_stopping], validation_data=([dev_X,dev_X_pos,dev_X_char], dev_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-qV6xzHQUXPh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WPRD2te1UXg7"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yZfsztrYBonv",
    "outputId": "c37ff928-190c-4be6-e9a8-4051f71a9b87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 91669, 2: 11581, 0: 840, 1: 175})\n"
     ]
    }
   ],
   "source": [
    "preds = np.argmax(model2.predict([dev_X,dev_X_pos,dev_X_char]), axis=-1)\n",
    "flat_preds = [p for pred in preds for p in pred]\n",
    "print(Counter(flat_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "V_WP3HliGHe-"
   },
   "outputs": [],
   "source": [
    "# corrected_preds = []\n",
    "\n",
    "# for item in (preds):\n",
    "#   preds_temp = item\n",
    "\n",
    "#   if preds_temp[0] == 1:\n",
    "#       preds_temp[0] = 0\n",
    "    \n",
    "#   for i in range(1,len(preds_temp)):\n",
    "#       if preds_temp[i] == 1:\n",
    "#         if preds_temp[i-1] == 2 :\n",
    "#           preds_temp[i] = 0\n",
    "\n",
    "#   corrected_preds.append(preds_temp)\n",
    "  \n",
    "#   preds = corrected_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "id": "8XRBaoq8Bodk",
    "outputId": "258dd80c-cd6f-4c28-94b8-26affe94a437"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hu/miniconda3/envs/dev/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_num</th>\n",
       "      <th>token</th>\n",
       "      <th>bio_only</th>\n",
       "      <th>token_indices</th>\n",
       "      <th>upos</th>\n",
       "      <th>pos_indices</th>\n",
       "      <th>char_list</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[Stabilized, approach, or, not, ?, That, Â´, s,...</td>\n",
       "      <td>[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...</td>\n",
       "      <td>[14801.0, 10361.0, 414.0, 556.0, 131.0, 1740.0...</td>\n",
       "      <td>[PROPN, NOUN, CCONJ, PART, PUNCT, PRON, SYM, P...</td>\n",
       "      <td>[9.0, 0.0, 16.0, 15.0, 8.0, 1.0, 10.0, 15.0, 1...</td>\n",
       "      <td>[[25, 67, 26, 22, 32, 43, 32, 3, 49, 30], [26,...</td>\n",
       "      <td>[0, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_num                                              token  \\\n",
       "0             0  [Stabilized, approach, or, not, ?, That, Â´, s,...   \n",
       "\n",
       "                                            bio_only  \\\n",
       "0  [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...   \n",
       "\n",
       "                                       token_indices  \\\n",
       "0  [14801.0, 10361.0, 414.0, 556.0, 131.0, 1740.0...   \n",
       "\n",
       "                                                upos  \\\n",
       "0  [PROPN, NOUN, CCONJ, PART, PUNCT, PRON, SYM, P...   \n",
       "\n",
       "                                         pos_indices  \\\n",
       "0  [9.0, 0.0, 16.0, 15.0, 8.0, 1.0, 10.0, 15.0, 1...   \n",
       "\n",
       "                                           char_list  \\\n",
       "0  [[25, 67, 26, 22, 32, 43, 32, 3, 49, 30], [26,...   \n",
       "\n",
       "                             prediction  \n",
       "0  [0, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    dev_seqs['prediction'] = ''\n",
    "\n",
    "    # for each text: get original sequence length and trim predictions accordingly\n",
    "    # (_trim_ because we know that our seq length is longer than the longest seq in dev)\n",
    "    for i in dev_seqs.index:\n",
    "      this_seq_length = len(dev_seqs['token'][i])\n",
    "      dev_seqs['prediction'][i] = preds[i][:this_seq_length].astype(int)\n",
    "\n",
    "    dev_seqs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "gHbQe6TiBoLP",
    "outputId": "ee19db2e-2992-4413-bee3-ffd98d1c80cf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_num</th>\n",
       "      <th>token</th>\n",
       "      <th>bio_only</th>\n",
       "      <th>token_indices</th>\n",
       "      <th>upos</th>\n",
       "      <th>pos_indices</th>\n",
       "      <th>char_list</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Stabilized</td>\n",
       "      <td>2</td>\n",
       "      <td>14801</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>9</td>\n",
       "      <td>[25, 67, 26, 22, 32, 43, 32, 3, 49, 30]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_num       token bio_only token_indices   upos pos_indices  \\\n",
       "0             0  Stabilized        2         14801  PROPN           9   \n",
       "\n",
       "                                 char_list prediction  \n",
       "0  [25, 67, 26, 22, 32, 43, 32, 3, 49, 30]          0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_long = dev_seqs.set_index('sequence_num').apply(pd.Series.explode).reset_index()\n",
    "dev_long.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "waI5lvpDFrC8"
   },
   "outputs": [],
   "source": [
    "# re-using the BIO integer-to-character function from last time\n",
    "def reverse_bio(ind):\n",
    "  bio = 'O'  # for any pad=3 predictions\n",
    "  if ind==0:\n",
    "    bio = 'B'\n",
    "  elif ind==1:\n",
    "    bio = 'I'\n",
    "  elif ind==2:\n",
    "    bio = 'O'\n",
    "  return bio\n",
    "\n",
    "bio_labs = [reverse_bio(b) for b in dev_long['bio_only']]\n",
    "dev_long['bio_only'] = bio_labs\n",
    "pred_labs = [reverse_bio(b) for b in dev_long['prediction']]\n",
    "dev_long['prediction'] = pred_labs\n",
    "\n",
    "dev_long.head()\n",
    "dev_long.prediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LrIWppkaFB5P",
    "outputId": "05a4f5de-c00f-4d3a-b489-c47700ec7ace"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O    14367\n",
       "B      840\n",
       "I      175\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-using the BIO integer-to-character function from last time\n",
    "def reverse_bio(ind):\n",
    "  bio = 'O'  # for any pad=3 predictions\n",
    "  if ind==0:\n",
    "    bio = 'B'\n",
    "  elif ind==1:\n",
    "    bio = 'I'\n",
    "  elif ind==2:\n",
    "    bio = 'O'\n",
    "  return bio\n",
    "\n",
    "bio_labs = [reverse_bio(b) for b in dev_long['bio_only']]\n",
    "dev_long['bio_only'] = bio_labs\n",
    "pred_labs = [reverse_bio(b) for b in dev_long['prediction']]\n",
    "dev_long['prediction'] = pred_labs\n",
    "\n",
    "dev_long.head()\n",
    "dev_long.prediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eqloxUGvFmzc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-JkZnTAYc9t"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FkYK7R4HFBr7",
    "outputId": "a8ef206a-2a32-4a04-fa02-25df619b4a88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of TP and FP = 733\n",
      "Sum of TP and FN = 797\n",
      "True positives = 380, False positives = 353, False negatives = 417\n",
      "Precision = 0.518, Recall = 0.477, F1 = 0.497 (max=1)\n"
     ]
    }
   ],
   "source": [
    "def wnut_evaluate(txt):\n",
    "  '''row by row entity evaluation: we evaluate by whole named entities'''\n",
    "  tp = 0; fp = 0; fn = 0\n",
    "  in_entity = 0\n",
    "  for i in txt.index:\n",
    "    if txt['prediction'][i]=='B' and txt['bio_only'][i]=='B':\n",
    "      if in_entity==1:  # if there's a preceding named entity which didn't have intervening O...\n",
    "        tp += 1  # count a true positive\n",
    "      in_entity = 1  # start tracking this entity (don't count it until we know full span of entity)\n",
    "    elif txt['prediction'][i]=='B':\n",
    "      fp += 1  # if not a B in gold annotations, it's a false positive\n",
    "      in_entity = 0\n",
    "    elif txt['prediction'][i]=='I' and txt['bio_only'][i]=='I':\n",
    "      next  # correct entity continuation: do nothing\n",
    "    elif txt['prediction'][i]=='I' and txt['bio_only'][i]=='B':\n",
    "      fn += 1  # if a new entity should have begun, it's a false negative\n",
    "      in_entity = 0\n",
    "    elif txt['prediction'][i]=='I':  # if gold is O...\n",
    "      if in_entity==1:  # and if tracking an entity, then the span is too long\n",
    "        fp += 1  # it's a false positive\n",
    "      in_entity = 0\n",
    "    elif txt['prediction'][i]=='O':\n",
    "      if txt['bio_only'][i]=='B':\n",
    "        fn += 1  # false negative if there's B in gold but no predicted B\n",
    "        if in_entity==1:  # also check if there was a named entity in progress\n",
    "          tp += 1  # count a true positive\n",
    "      elif txt['bio_only'][i]=='I':\n",
    "        if in_entity==1:  # if this should have been a continued named entity, the span is too short\n",
    "          fn += 1  # count a false negative\n",
    "      elif txt['bio_only'][i]=='O':\n",
    "        if in_entity==1:  # if a named entity has ended in right place\n",
    "          tp += 1  # count a true positive\n",
    "      in_entity = 0\n",
    "\n",
    "  if in_entity==1:  # catch any final named entity\n",
    "    tp += 1\n",
    "\n",
    "  print('Sum of TP and FP = %i' % (tp+fp))\n",
    "  print('Sum of TP and FN = %i' % (tp+fn))\n",
    "  print('True positives = %i, False positives = %i, False negatives = %i' % (tp, fp, fn))\n",
    "  prec = tp / (tp+fp)\n",
    "  rec = tp / (tp+fn)\n",
    "  f1 = (2*(prec*rec)) / (prec+rec)\n",
    "  print('Precision = %.3f, Recall = %.3f, F1 = %.3f (max=1)' % (prec, rec, f1))\n",
    " \n",
    "wnut_evaluate(dev_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "YQzU3ngQFBgW"
   },
   "outputs": [],
   "source": [
    "    dev_long.to_csv('FullChar_POS.txt', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ycwMJhUSFJlO",
    "outputId": "492db2a1-4c67-4d84-ada6-275627631042"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-3.04704439e-02 -2.76493188e-02  2.69191600e-02 ...  8.50858539e-03\n",
      "    2.46909373e-02 -8.24428722e-03]\n",
      "  [-3.71010900e-02  4.32311185e-02  1.05293170e-02 ... -7.49167055e-03\n",
      "    5.51857054e-04  4.66991924e-02]\n",
      "  [-3.55623141e-02  4.45062630e-02 -2.62874719e-02 ...  3.10262926e-02\n",
      "    9.06201452e-03  1.36376284e-02]\n",
      "  ...\n",
      "  [-7.28629902e-03  6.90187141e-03  2.21623071e-02 ...  3.22265737e-02\n",
      "    1.68389119e-02 -2.97251344e-02]\n",
      "  [-2.44478118e-02  4.82443720e-03  3.62755768e-02 ...  7.80452043e-04\n",
      "    1.10337846e-02 -4.74399440e-02]\n",
      "  [-3.79296765e-02 -1.76474564e-02  2.28854455e-02 ... -6.39337301e-03\n",
      "    3.35512049e-02  2.52128728e-02]]\n",
      "\n",
      " [[ 2.28893198e-02  3.84732746e-02  4.30743769e-03 ...  1.71151012e-03\n",
      "   -3.42347398e-02  4.54065688e-02]\n",
      "  [ 3.24051045e-02  5.02653047e-03  4.08249758e-02 ... -2.93975826e-02\n",
      "   -1.30207762e-02 -2.33641267e-02]\n",
      "  [ 4.55523469e-02 -1.70677900e-03 -7.90727139e-03 ...  1.20730177e-02\n",
      "    4.93777432e-02  2.08526738e-02]\n",
      "  ...\n",
      "  [-3.35530043e-02 -3.07900794e-02 -1.49565339e-02 ...  6.50329515e-03\n",
      "   -1.65262595e-02  1.84316151e-02]\n",
      "  [ 3.08255069e-02  2.20410116e-02 -1.67389028e-02 ...  3.92087586e-02\n",
      "    3.11891176e-02  8.13747570e-03]\n",
      "  [-3.91189083e-02  1.34764053e-02  3.53026502e-02 ... -1.58234015e-02\n",
      "    1.70708820e-03  1.03143454e-02]]\n",
      "\n",
      " [[ 3.17496918e-02 -2.20625643e-02 -1.80128589e-02 ... -2.49431487e-02\n",
      "   -3.00710201e-02 -3.12196501e-02]\n",
      "  [-1.49576068e-02 -2.97055487e-02 -1.65600292e-02 ...  4.07017767e-04\n",
      "   -3.01685575e-02  4.87889089e-02]\n",
      "  [-3.01473867e-02  4.82467562e-03 -3.88498418e-02 ...  3.26783583e-03\n",
      "   -4.94553708e-02  1.44150965e-02]\n",
      "  ...\n",
      "  [ 4.54764441e-03 -3.00937649e-02  4.43776734e-02 ...  1.54689215e-02\n",
      "    4.90876473e-02 -2.49189138e-03]\n",
      "  [ 4.48257364e-02 -1.04009621e-02 -4.95355204e-03 ... -1.84685364e-02\n",
      "    4.23227660e-02  4.30992506e-02]\n",
      "  [ 1.61082260e-02  2.67059319e-02  4.66537476e-03 ... -9.50577110e-03\n",
      "    1.89248957e-02 -4.47548740e-02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-2.44478118e-02  4.82443720e-03  3.62755768e-02 ...  7.80452043e-04\n",
      "    1.10337846e-02 -4.74399440e-02]\n",
      "  [ 1.39894374e-02  1.17979534e-02  1.02687851e-02 ...  4.02781256e-02\n",
      "    3.64932679e-02  3.64607461e-02]\n",
      "  [ 2.35272571e-03  3.35154869e-02 -4.96444106e-02 ... -2.79202219e-02\n",
      "    4.66588251e-02  1.84607245e-02]\n",
      "  ...\n",
      "  [ 1.71712749e-02  6.60924986e-03  1.87152363e-02 ...  1.19549856e-02\n",
      "    4.55743335e-02  1.08014420e-03]\n",
      "  [-3.18040028e-02 -3.21888812e-02 -1.66636482e-02 ... -1.29030123e-02\n",
      "   -2.85827275e-02 -6.39501959e-03]\n",
      "  [-2.95427684e-02  3.98129709e-02  3.37212794e-02 ... -4.77392785e-02\n",
      "    4.04095165e-02 -3.03402673e-02]]\n",
      "\n",
      " [[-4.90521565e-02  6.56469911e-03 -1.32479519e-03 ... -9.86564159e-03\n",
      "   -3.87244336e-02  4.97272871e-02]\n",
      "  [-3.32964435e-02  2.21015476e-02  4.33917157e-02 ... -3.67315412e-02\n",
      "    2.37891339e-02 -3.34653743e-02]\n",
      "  [-1.90324672e-02 -1.08692050e-02  3.22485082e-02 ...  2.56088041e-02\n",
      "    3.40059884e-02  9.46701691e-03]\n",
      "  ...\n",
      "  [-2.20712908e-02  5.42453676e-03  4.88607325e-02 ...  3.05160992e-02\n",
      "   -1.75331235e-02  3.50139178e-02]\n",
      "  [-7.43532181e-03 -4.20026407e-02  4.03139107e-02 ... -3.77160683e-02\n",
      "   -2.06927210e-03  4.63880785e-02]\n",
      "  [ 4.95988466e-02 -3.54816765e-03 -6.28926605e-03 ... -7.62916729e-03\n",
      "    1.42428167e-02  7.68189505e-03]]\n",
      "\n",
      " [[ 2.26210989e-02 -2.88310535e-02  3.14545631e-03 ... -8.20728391e-03\n",
      "   -1.10910535e-02 -1.16034634e-02]\n",
      "  [-4.37420495e-02 -4.53045852e-02  3.02719958e-02 ...  4.63882945e-02\n",
      "   -3.41586098e-02  3.55428942e-02]\n",
      "  [-3.22010666e-02  4.98235114e-02  9.73303244e-03 ... -2.55686771e-02\n",
      "   -2.04548836e-02  3.75081189e-02]\n",
      "  ...\n",
      "  [-7.91614130e-03 -3.29965502e-02  2.11943276e-02 ... -1.76343434e-02\n",
      "    2.66338252e-02  4.19459678e-02]\n",
      "  [-1.10954866e-02  1.61607899e-02  2.47103833e-02 ... -5.38122654e-03\n",
      "   -4.90947962e-02  1.76347010e-02]\n",
      "  [-4.73991632e-02 -2.76251882e-03  4.47080620e-02 ... -1.92368980e-02\n",
      "   -7.65807927e-05  4.52334993e-02]]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "import numpy as np\n",
    " \n",
    "model = Sequential()\n",
    "model.add(Embedding(1000, 64, input_length=10))\n",
    "# è¾å¥å¤§å°ä¸º(Noneï¼10)ï¼Nnoeæ¯batch_sizeå¤§å°ï¼10ä»£è¡¨æ¯ä¸ä¸ªbatchä¸­æ10æ¡æ ·æ¬\n",
    "# è¾åºå¤§å°ä¸º(None, 10, 64),å¶ä¸­64ä»£è¡¨è¾å¥ä¸­æ¯ä¸ªæ¯æ¡æ ·æ¬è¢«embeddingæäº64ç»´çåé\n",
    " \n",
    "input_array = np.random.randint(1000, size=(32, 10))\n",
    "\n",
    "\n",
    "\n",
    "model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict(input_array)\n",
    "print(output_array)\n",
    "assert output_array.shape == (32, 10, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w4NPFCfWlaJx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E_GwiqibFBUc",
    "outputId": "945e1fbf-f94f-41fd-972a-2a5408145a32"
   },
   "outputs": [
    {
     "ename": "UnknownError",
     "evalue": " [_Derived_]  Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[model_3/lstm_6/StatefulPartitionedCall]] [Op:__inference_predict_function_53959]\n\nFunction call stack:\npredict_function -> predict_function -> predict_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-17ff9870d268>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0minputs1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlstm2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1266\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m             \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    648\u001b[0m               *args, **kwds)\n\u001b[1;32m    649\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/miniconda3/envs/dev/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnknownError\u001b[0m:  [_Derived_]  Fail to find the dnn implementation.\n\t [[{{node CudnnRNN}}]]\n\t [[model_3/lstm_6/StatefulPartitionedCall]] [Op:__inference_predict_function_53959]\n\nFunction call stack:\npredict_function -> predict_function -> predict_function\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(0)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(0)\n",
    "\n",
    "\n",
    "data = array([0.1,0.2,0.3]).reshape((1,3,1))\n",
    "inputs1 = Input(shape=(3,1))\n",
    "lstm1,state_h,state_c = LSTM(2,return_sequences=True,return_state=True)(inputs1) #ç¬¬ä¸å±LSTM\n",
    "lstm2 = LSTM(2,return_sequences=False)(lstm1)  #ç¬¬äºå±LSTM\n",
    "model = Model( inputs1,outputs = [lstm2])\n",
    "\n",
    "print(model.predict(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "blCY6spaFAkg"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6uVFTZL3mmVZ",
    "outputId": "df887ca7-2ad6-4191-ec1e-69e7d7c28e15"
   },
   "outputs": [],
   "source": [
    "path = keras.utils.get_file(\n",
    "    \"nietzsche.txt\", origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\"\n",
    ")\n",
    "with io.open(path, encoding=\"utf-8\") as f:\n",
    "    text = f.read().lower()\n",
    "text = text.replace(\"\\n\", \" \")  # We remove newlines chars for nicer display\n",
    "print(\"Corpus length:\", len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print(\"Total chars:\", len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i : i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print(\"Number of sequences:\", len(sentences))\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hoHMwGHgmmSA",
    "outputId": "dbafc948-5f27-452c-c630-69b24fa5d1c9"
   },
   "outputs": [],
   "source": [
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-J4FduPmmOc",
    "outputId": "85dc2b7c-1217-4b87-fda0-4d21e9a294f3"
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iLv5A-TgmmI4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yYGnJLTfml-a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGjpY1r2mlvK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2yGaegnmlWh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "LSTMwithFullEmbeddingandPOS",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
