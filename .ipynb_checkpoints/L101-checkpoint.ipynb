{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "import collections\n",
    "import operator\n",
    "from functools import reduce\n",
    "import json\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Lazy Load) Loading model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['艹', '丿', '日', '王']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xmnlp\n",
    "xmnlp.radical('花丸晴琉')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build up Chinese sub-character unites diactionary.\n",
    "\n",
    "chaiZi_Dic = {}\n",
    "with open(\"./corpus/chaizi/chaizi-jt.txt\", 'r') as f:\n",
    "    reader = csv.reader(f,delimiter='\\t')\n",
    "    for row in reader:\n",
    "        chaiZi_Dic[row[0]] = row[1]\n",
    "        \n",
    "def getSubChar(charCN):\n",
    "    if(charCN in chaiZi_Dic.keys()):\n",
    "        return chaiZi_Dic[item]\n",
    "    else:\n",
    "        return [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14563\n",
      "草 化\n",
      "['艹']\n",
      "\n",
      "丶 九\n",
      "['丿']\n",
      "\n",
      "[None]\n",
      "[None]\n",
      "\n",
      "日 青\n",
      "['日']\n",
      "\n",
      "玉 亠 厶 川\n",
      "['王']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(chaiZi_Dic.keys()))\n",
    "for item in \"花丸A晴琉\":\n",
    "    print(getSubChar(item))\n",
    "    print(xmnlp.radical(item))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Corpus for Chinese Word Segamentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>迈向  充满  希望  的  新  世纪  ——  一九九八年  新年  讲话  （  附 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input\n",
       "0  迈向  充满  希望  的  新  世纪  ——  一九九八年  新年  讲话  （  附 ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pkuTrain = \"./corpus/cws/icwb2-data/training/pku_training.utf8\"\n",
    "train = pd.read_table(pkuTrain,  encoding='utf8', header=None, names=['input'])  # don't drop the empty lines yet, they show up as NaN in the data frame\n",
    "train.head(n=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19054\n"
     ]
    }
   ],
   "source": [
    "def prepross_data(train_Data):\n",
    "    inputs = train_Data[\"input\"][:]\n",
    "    print(len(inputs))\n",
    "    raws = []\n",
    "    tokenList = []\n",
    "    \n",
    "    for item in inputs:\n",
    "        item = item.replace(\"   \", \"  \")\n",
    "\n",
    "        raw = item.replace(\" \", \"\")\n",
    "#         print(item)\n",
    "#         print(raw)\n",
    "        raws.append(raw)\n",
    "        tokens = (item.split(\"  \")[:-1])\n",
    "        tokenList.append(tokens)\n",
    "#         print(tokens)\n",
    "    train_Data[\"raws\"] = raws\n",
    "    train_Data[\"tokenList\"] = tokenList\n",
    "    dictionary_train_word = list(set(reduce(operator.add,train_Data[\"tokenList\"])))\n",
    "    dictionary_train_char =  list(set(reduce(operator.add,train_Data[\"raws\"])))    \n",
    "    return train_Data, dictionary_train_char, dictionary_train_word\n",
    "train, train_dic_char, train_dic_word  = prepross_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the pre-processing\n",
    "def validate_data(data):\n",
    "    \n",
    "    tkList = data[\"tokenList\"]\n",
    "    raws = data[\"raws\"]\n",
    "    \n",
    "    for (tokens, raw) in zip(tkList,raws):\n",
    "#         print(tokens)\n",
    "        \n",
    "#         print(raw)\n",
    "        temp  = \"\".join(tokens)\n",
    "#         print(temp)\n",
    "        assert(temp == raw)\n",
    "        if not (temp == raw):\n",
    "            print(temp)\n",
    "            print(raw)\n",
    "            print(tokens)\n",
    "validate_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>raws</th>\n",
       "      <th>tokenList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>迈向  充满  希望  的  新  世纪  ——  一九九八年  新年  讲话  （  附 ...</td>\n",
       "      <td>迈向充满希望的新世纪——一九九八年新年讲话（附图片１张）</td>\n",
       "      <td>[迈向, 充满, 希望, 的, 新, 世纪, ——, 一九九八年, 新年, 讲话, （, 附...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>中共中央  总书记  、  国家  主席  江  泽民</td>\n",
       "      <td>中共中央总书记、国家主席江泽民</td>\n",
       "      <td>[中共中央, 总书记, 、, 国家, 主席, 江, 泽民]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>（  一九九七年  十二月  三十一日  ）</td>\n",
       "      <td>（一九九七年十二月三十一日）</td>\n",
       "      <td>[（, 一九九七年, 十二月, 三十一日, ）]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>１２月  ３１日  ，  中共中央  总书记  、  国家  主席  江  泽民  发表  ...</td>\n",
       "      <td>１２月３１日，中共中央总书记、国家主席江泽民发表１９９８年新年讲话《迈向充满希望的新世纪》。...</td>\n",
       "      <td>[１２月, ３１日, ，, 中共中央, 总书记, 、, 国家, 主席, 江, 泽民, 发表,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>同胞  们  、  朋友  们  、  女士  们  、  先生  们  ：</td>\n",
       "      <td>同胞们、朋友们、女士们、先生们：</td>\n",
       "      <td>[同胞, 们, 、, 朋友, 们, 、, 女士, 们, 、, 先生, 们, ：]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  迈向  充满  希望  的  新  世纪  ——  一九九八年  新年  讲话  （  附 ...   \n",
       "1                      中共中央  总书记  、  国家  主席  江  泽民     \n",
       "2                           （  一九九七年  十二月  三十一日  ）     \n",
       "3  １２月  ３１日  ，  中共中央  总书记  、  国家  主席  江  泽民  发表  ...   \n",
       "4           同胞  们  、  朋友  们  、  女士  们  、  先生  们  ：     \n",
       "\n",
       "                                                raws  \\\n",
       "0                       迈向充满希望的新世纪——一九九八年新年讲话（附图片１张）   \n",
       "1                                    中共中央总书记、国家主席江泽民   \n",
       "2                                     （一九九七年十二月三十一日）   \n",
       "3  １２月３１日，中共中央总书记、国家主席江泽民发表１９９８年新年讲话《迈向充满希望的新世纪》。...   \n",
       "4                                   同胞们、朋友们、女士们、先生们：   \n",
       "\n",
       "                                           tokenList  \n",
       "0  [迈向, 充满, 希望, 的, 新, 世纪, ——, 一九九八年, 新年, 讲话, （, 附...  \n",
       "1                      [中共中央, 总书记, 、, 国家, 主席, 江, 泽民]  \n",
       "2                           [（, 一九九七年, 十二月, 三十一日, ）]  \n",
       "3  [１２月, ３１日, ，, 中共中央, 总书记, 、, 国家, 主席, 江, 泽民, 发表,...  \n",
       "4           [同胞, 们, 、, 朋友, 们, 、, 女士, 们, 、, 先生, 们, ：]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4698\n",
      "4698\n",
      "55303\n",
      "55303\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dic_char))\n",
    "print(len(set(train_dic_char)))\n",
    "print(len(train_dic_word))\n",
    "print(len(set(train_dic_word)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55303\n"
     ]
    }
   ],
   "source": [
    "train_words = []\n",
    "with open(\"./corpus/cws/icwb2-data/gold/pku_training_words.utf8\", 'r') as f:\n",
    "    content = f.readlines()  \n",
    "    print(len(content))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4698\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction\n",
    "\n",
    "oov = len(train_dic_char)\n",
    "print(oov)\n",
    "def token_index(tok):\n",
    "    ind = tok\n",
    "    if tok in train_dic_char:  # if token in vocabulary\n",
    "        ind = train_dic_char.index(tok)\n",
    "    else:  # else it's OOV\n",
    "        ind = oov\n",
    "    return ind\n",
    "\n",
    "def str_token_index(string):\n",
    "    return [token_index(x)   for x in string]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# training labels: convert BIO to integers\n",
    "# def bio_index(bio):\n",
    "#     ind = bio\n",
    "#     if not pd.isnull(bio):  # deal with empty lines\n",
    "#         if bio=='B':\n",
    "#             ind = 0\n",
    "#         elif bio=='I':\n",
    "#             ind = 1\n",
    "#         elif bio=='O':\n",
    "#             ind = 2\n",
    "#     return ind\n",
    "\n",
    "# Get Begin Middle End Single sequence\n",
    "# B 0 M 1 E 2 S 3\n",
    "\n",
    "def str_bmes_idx(tokenList):\n",
    "    answer = []\n",
    "    for item in tokenList:\n",
    "        if len(item) == 0:\n",
    "            raise NameErro(\"Zero Length Word\")\n",
    "        if len(item) == 1:\n",
    "            answer.append(3)\n",
    "        else:\n",
    "            answer.append(0)\n",
    "            for item in range(len(item) - 2):\n",
    "                answer.append(1)\n",
    "            answer.append(2)\n",
    "    return answer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_features(data_set, istest=False):\n",
    "    data_temp = data_set.copy()\n",
    "    \n",
    "\n",
    "    # Idx for chars\n",
    "    with Pool(8) as p:\n",
    "        tokinds = p.map(str_token_index,data_temp['raws'])\n",
    "#     tokinds = [list(map(token_index, u)) for u in data_temp['raws']]\n",
    "    data_temp[\"tokenIdx\"] = tokinds\n",
    "    \n",
    "    # BIO\n",
    "    data_temp[\"bmes\"] = [str_bmes_idx(u) for u in data_temp['tokenList']]\n",
    "#     print(data_temp[\"bmes\"])\n",
    "    assert (list(map(len,data_temp[\"bmes\"])) == list(map(len,data_temp[\"tokenIdx\"])))\n",
    "#    assert reduce(operator.and_, list(map(len,data_temp[\"bmes\"])) == list(map(len,data_temp[\"tokenIdx\"])))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return data_temp\n",
    "#     txt['token_indices'] = tokinds\n",
    "#     if not istest:  # can't do this with the test set\n",
    "#         bioints = [bio_index(b) for b in txt['bio_only']]\n",
    "#         txt['bio_only'] = bioints\n",
    "#     return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      ":D\n",
      "CPU times: user 423 ms, sys: 163 ms, total: 586 ms\n",
      "Wall time: 14.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# MultiThreading\n",
    "temp = extract_features(train)\n",
    "tempa = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 36s, sys: 27.9 ms, total: 1min 36s\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "temp = extract_features(train)\n",
    "tempb = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert reduce(operator.and_, tempa[\"tokenIdx\"] == tempb[\"tokenIdx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>raws</th>\n",
       "      <th>tokenList</th>\n",
       "      <th>tokenIdx</th>\n",
       "      <th>bmes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>迈向  充满  希望  的  新  世纪  ——  一九九八年  新年  讲话  （  附 ...</td>\n",
       "      <td>迈向充满希望的新世纪——一九九八年新年讲话（附图片１张）</td>\n",
       "      <td>[迈向, 充满, 希望, 的, 新, 世纪, ——, 一九九八年, 新年, 讲话, （, 附...</td>\n",
       "      <td>[84, 2326, 46, 166, 610, 719, 2511, 4631, 134,...</td>\n",
       "      <td>[0, 2, 0, 2, 0, 2, 3, 3, 0, 2, 0, 2, 0, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>中共中央  总书记  、  国家  主席  江  泽民</td>\n",
       "      <td>中共中央总书记、国家主席江泽民</td>\n",
       "      <td>[中共中央, 总书记, 、, 国家, 主席, 江, 泽民]</td>\n",
       "      <td>[3347, 3041, 3347, 2471, 748, 1363, 1566, 3411...</td>\n",
       "      <td>[0, 1, 1, 2, 0, 1, 2, 3, 0, 2, 0, 2, 3, 0, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>（  一九九七年  十二月  三十一日  ）</td>\n",
       "      <td>（一九九七年十二月三十一日）</td>\n",
       "      <td>[（, 一九九七年, 十二月, 三十一日, ）]</td>\n",
       "      <td>[1978, 2468, 226, 226, 1833, 4457, 2831, 2242,...</td>\n",
       "      <td>[3, 0, 1, 1, 1, 2, 0, 1, 2, 0, 1, 1, 2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>１２月  ３１日  ，  中共中央  总书记  、  国家  主席  江  泽民  发表  ...</td>\n",
       "      <td>１２月３１日，中共中央总书记、国家主席江泽民发表１９９８年新年讲话《迈向充满希望的新世纪》。...</td>\n",
       "      <td>[１２月, ３１日, ，, 中共中央, 总书记, 、, 国家, 主席, 江, 泽民, 发表,...</td>\n",
       "      <td>[1954, 330, 1504, 807, 1954, 3037, 1902, 3347,...</td>\n",
       "      <td>[0, 1, 2, 0, 1, 2, 3, 0, 1, 1, 2, 0, 1, 2, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>同胞  们  、  朋友  们  、  女士  们  、  先生  们  ：</td>\n",
       "      <td>同胞们、朋友们、女士们、先生们：</td>\n",
       "      <td>[同胞, 们, 、, 朋友, 们, 、, 女士, 们, 、, 先生, 们, ：]</td>\n",
       "      <td>[32, 319, 3474, 3411, 2463, 3291, 3474, 3411, ...</td>\n",
       "      <td>[0, 2, 3, 3, 0, 2, 3, 3, 0, 2, 3, 3, 0, 2, 3, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  迈向  充满  希望  的  新  世纪  ——  一九九八年  新年  讲话  （  附 ...   \n",
       "1                      中共中央  总书记  、  国家  主席  江  泽民     \n",
       "2                           （  一九九七年  十二月  三十一日  ）     \n",
       "3  １２月  ３１日  ，  中共中央  总书记  、  国家  主席  江  泽民  发表  ...   \n",
       "4           同胞  们  、  朋友  们  、  女士  们  、  先生  们  ：     \n",
       "\n",
       "                                                raws  \\\n",
       "0                       迈向充满希望的新世纪——一九九八年新年讲话（附图片１张）   \n",
       "1                                    中共中央总书记、国家主席江泽民   \n",
       "2                                     （一九九七年十二月三十一日）   \n",
       "3  １２月３１日，中共中央总书记、国家主席江泽民发表１９９８年新年讲话《迈向充满希望的新世纪》。...   \n",
       "4                                   同胞们、朋友们、女士们、先生们：   \n",
       "\n",
       "                                           tokenList  \\\n",
       "0  [迈向, 充满, 希望, 的, 新, 世纪, ——, 一九九八年, 新年, 讲话, （, 附...   \n",
       "1                      [中共中央, 总书记, 、, 国家, 主席, 江, 泽民]   \n",
       "2                           [（, 一九九七年, 十二月, 三十一日, ）]   \n",
       "3  [１２月, ３１日, ，, 中共中央, 总书记, 、, 国家, 主席, 江, 泽民, 发表,...   \n",
       "4           [同胞, 们, 、, 朋友, 们, 、, 女士, 们, 、, 先生, 们, ：]   \n",
       "\n",
       "                                            tokenIdx  \\\n",
       "0  [84, 2326, 46, 166, 610, 719, 2511, 4631, 134,...   \n",
       "1  [3347, 3041, 3347, 2471, 748, 1363, 1566, 3411...   \n",
       "2  [1978, 2468, 226, 226, 1833, 4457, 2831, 2242,...   \n",
       "3  [1954, 330, 1504, 807, 1954, 3037, 1902, 3347,...   \n",
       "4  [32, 319, 3474, 3411, 2463, 3291, 3474, 3411, ...   \n",
       "\n",
       "                                                bmes  \n",
       "0  [0, 2, 0, 2, 0, 2, 3, 3, 0, 2, 0, 2, 0, 1, 1, ...  \n",
       "1      [0, 1, 1, 2, 0, 1, 2, 3, 0, 2, 0, 2, 3, 0, 2]  \n",
       "2         [3, 0, 1, 1, 1, 2, 0, 1, 2, 0, 1, 1, 2, 3]  \n",
       "3  [0, 1, 2, 0, 1, 2, 3, 0, 1, 1, 2, 0, 1, 2, 3, ...  \n",
       "4   [0, 2, 3, 3, 0, 2, 3, 3, 0, 2, 3, 3, 0, 2, 3, 3]  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_longest_sequence(txt):\n",
    "  '''find the longest sequence in the dataframe'''\n",
    "  for i in txt.index:\n",
    "    seqlen = len(txt['token'][i])\n",
    "    if seqlen > longest_seq:  # update high water mark if new longest sequence encountered\n",
    "      longest_seq = seqlen\n",
    "  return longest_seq\n",
    "\n",
    "train_longest = find_longest_sequence(train_seqs,0)\n",
    "print('The longest sequence in the training set is %i tokens long' % train_longest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
