{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "rS1KRgyJzRYZ",
    "outputId": "ee0395a9-efe3-4ec1-a770-5ecb4aa55813"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>bio_only</th>\n",
       "      <th>upos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@paulwalk</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token label bio_only  upos\n",
       "0  @paulwalk     O        O  NOUN"
      ]
     },
     "execution_count": 276,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "wnuttrain = 'https://storage.googleapis.com/wnut-2017_ner-shared-task/wnut17train_clean_tagged.txt'\n",
    "train = pd.read_table(wnuttrain, header=None, names=['token', 'label', 'bio_only', 'upos'])  # don't drop the empty lines yet, they show up as NaN in the data frame\n",
    "train.head(n=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2j2ZkRxuqCok"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oTtvqwpNzgVR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "i7fjK0PJzVFS",
    "outputId": "3c8b507e-5e32-4f0b-ae95-4e997b7c4bdb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>bio_only</th>\n",
       "      <th>upos</th>\n",
       "      <th>token_indices</th>\n",
       "      <th>pos_indices</th>\n",
       "      <th>char_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@paulwalk</td>\n",
       "      <td>O</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[24, 56, 27, 47, 8, 3, 27, 8, 82]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It</td>\n",
       "      <td>O</td>\n",
       "      <td>2.0</td>\n",
       "      <td>PRON</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[16, 90]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'s</td>\n",
       "      <td>O</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AUX</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[23, 41]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "      <td>2.0</td>\n",
       "      <td>DET</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>[90, 4, 35]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>view</td>\n",
       "      <td>O</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[9, 81, 35, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>from</td>\n",
       "      <td>O</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ADP</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[19, 39, 21, 84]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>where</td>\n",
       "      <td>O</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ADV</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[3, 4, 35, 39, 35]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I</td>\n",
       "      <td>O</td>\n",
       "      <td>2.0</td>\n",
       "      <td>PRON</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'m</td>\n",
       "      <td>O</td>\n",
       "      <td>2.0</td>\n",
       "      <td>X</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>[23, 84]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>living</td>\n",
       "      <td>O</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[8, 81, 9, 81, 61, 7]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       token label  ...  pos_indices                          char_list\n",
       "0  @paulwalk     O  ...          0.0  [24, 56, 27, 47, 8, 3, 27, 8, 82]\n",
       "1         It     O  ...          1.0                           [16, 90]\n",
       "2         's     O  ...          2.0                           [23, 41]\n",
       "3        the     O  ...          3.0                        [90, 4, 35]\n",
       "4       view     O  ...          0.0                     [9, 81, 35, 3]\n",
       "5       from     O  ...          4.0                   [19, 39, 21, 84]\n",
       "6      where     O  ...          5.0                 [3, 4, 35, 39, 35]\n",
       "7          I     O  ...          1.0                               [16]\n",
       "8         'm     O  ...          6.0                           [23, 84]\n",
       "9     living     O  ...          0.0              [8, 81, 9, 81, 61, 7]\n",
       "\n",
       "[10 rows x 7 columns]"
      ]
     },
     "execution_count": 277,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Extraction\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "# in order to convert word tokens to integers: list the set of token types\n",
    "token_vocab = train.token.unique().tolist()\n",
    "oov = len(token_vocab)  # OOV (out of vocabulary) token as vocab length (because that's max.index + 1)\n",
    "\n",
    "\n",
    "# convert word tokens to integers\n",
    "def token_index(tok):\n",
    "  ind = tok\n",
    "  if not pd.isnull(tok):  # new since last time: deal with the empty lines which we didn't drop yet\n",
    "    if tok in token_vocab:  # if token in vocabulary\n",
    "      ind = token_vocab.index(tok)\n",
    "    else:  # else it's OOV\n",
    "      ind = oov\n",
    "  return ind\n",
    "\n",
    "\n",
    "#### DONE: Convert the POS Tag Into Integer.\n",
    "\n",
    "pos_vocab = train.upos.unique().tolist()\n",
    "oov_pos = len(pos_vocab)  # OOV (out of vocabulary) token as vocab length (because that's max.index + 1)\n",
    "# print(oov_pos)\n",
    "\n",
    "# Convert POS tag into Integers\n",
    "def pos_index(tok):\n",
    "  ind = tok\n",
    "  if not pd.isnull(tok):  # new since last time: deal with the empty lines which we didn't drop yet\n",
    "    if tok in pos_vocab:  # if token in vocabulary\n",
    "      ind = pos_vocab.index(tok)\n",
    "    else:  # else it's OOV\n",
    "      ind = oov_pos\n",
    "  return ind\n",
    "\n",
    "\n",
    "# training labels: convert BIO to integers\n",
    "def bio_index(bio):\n",
    "  ind = bio\n",
    "  if not pd.isnull(bio):  # deal with empty lines\n",
    "    if bio=='B':\n",
    "      ind = 0\n",
    "    elif bio=='I':\n",
    "      ind = 1\n",
    "    elif bio=='O':\n",
    "      ind = 2\n",
    "  return ind\n",
    "\n",
    "\n",
    "# Working Create Character Level Embedding\n",
    "\n",
    "\n",
    "# print(char_vocab)\n",
    "all_chars = set()\n",
    "for item in train.token:\n",
    "  if not (pd.isnull(item)):\n",
    "    for ch in item:\n",
    "      all_chars.add(ch)\n",
    "\n",
    "all_chars = list(all_chars)\n",
    "char_vocab = (all_chars)\n",
    "oov_char = len(char_vocab)\n",
    "\n",
    "\n",
    "# Convert Ch tag into Integers\n",
    "def char_index(word):\n",
    "  ans = []\n",
    "  if not pd.isnull(word):\n",
    "    for ch in word:\n",
    "      if ch in char_vocab:  # if token in vocabulary\n",
    "        ind = char_vocab.index(ch)\n",
    "      else:  # else it's OOV\n",
    "        ind = oov_char\n",
    "      ans.append(ind)\n",
    "    return ans\n",
    "  return []\n",
    "\n",
    "\n",
    "# pass a data frame through our feature extractor\n",
    "def extract_features(txt_orig,istest=False):\n",
    "  txt = txt_orig.copy()\n",
    "  tokinds = [token_index(u) for u in txt['token']]\n",
    "  txt['token_indices'] = tokinds\n",
    "\n",
    "\n",
    "  posinds = [pos_index(u) for u in txt['upos']]\n",
    "  txt['pos_indices'] = posinds\n",
    "\n",
    "  charsinds = [char_index(u) for u in txt['token']]\n",
    "\n",
    "  txt['char_list'] = charsinds\n",
    "\n",
    "\n",
    "  if not istest:  # can't do this with the test set\n",
    "    bioints = [bio_index(b) for b in txt['bio_only']]\n",
    "    txt['bio_only'] = bioints\n",
    "  return txt\n",
    "\n",
    "train_copy = extract_features(train)\n",
    "train_copy.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114
    },
    "id": "6Mz2z1O5zdp2",
    "outputId": "8c97e660-55dc-4994-b6a3-834add602fb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This cell takes a little while to run: be patient :)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_num</th>\n",
       "      <th>token</th>\n",
       "      <th>bio_only</th>\n",
       "      <th>token_indices</th>\n",
       "      <th>upos</th>\n",
       "      <th>pos_indices</th>\n",
       "      <th>char_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[@paulwalk, It, 's, the, view, from, where, I,...</td>\n",
       "      <td>[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>[NOUN, PRON, AUX, DET, NOUN, ADP, ADV, PRON, X...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 0.0, 4.0, 5.0, 1.0, 6.0, ...</td>\n",
       "      <td>[[24, 56, 27, 47, 8, 3, 27, 8, 82], [16, 90], ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_num  ...                                          char_list\n",
       "0             0  ...  [[24, 56, 27, 47, 8, 3, 27, 8, 82], [16, 90], ...\n",
       "\n",
       "[1 rows x 7 columns]"
      ]
     },
     "execution_count": 278,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokens2sequences(txt_orig,istest=False):\n",
    "  '''\n",
    "  Takes panda dataframe as input, copies, and adds a sequence index based on full-stops.\n",
    "  Outputs a dataframe with sequences of tokens, named entity labels, and token indices as lists.\n",
    "  '''\n",
    "  txt = txt_orig.copy()\n",
    "  txt['sequence_num'] = 0\n",
    "  seqcount = 0\n",
    "  for i in txt.index:  # in each row...\n",
    "    txt.loc[i,'sequence_num'] = seqcount  # set the sequence number\n",
    "    if pd.isnull(txt.loc[i,'token']):  # increment sequence counter at empty lines\n",
    "      seqcount += 1\n",
    "  # now drop the empty lines, group by sequence number and output df of sequence lists\n",
    "  txt = txt.dropna()\n",
    "  if istest:  # test set doesn't have labels\n",
    "    txt_seqs = txt.groupby(['sequence_num'],as_index=False)[['token', 'token_indices', \"upos\", \"pos_indices\",\"char_list\"]].agg(lambda x: list(x))\n",
    "  else:\n",
    "    txt_seqs = txt.groupby(['sequence_num'],as_index=False)[['token', 'bio_only', 'token_indices', 'upos', \"pos_indices\",\"char_list\"]].agg(lambda x: list(x))\n",
    "  return txt_seqs\n",
    "\n",
    "print(\"This cell takes a little while to run: be patient :)\")\n",
    "train_seqs = tokens2sequences(train_copy)\n",
    "train_seqs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "67XICD-Jz5j7",
    "outputId": "f17f1231-cdc2-4e3d-d914-3baebbf7021d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_num</th>\n",
       "      <th>token</th>\n",
       "      <th>bio_only</th>\n",
       "      <th>token_indices</th>\n",
       "      <th>upos</th>\n",
       "      <th>pos_indices</th>\n",
       "      <th>char_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@paulwalk</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0</td>\n",
       "      <td>[24, 56, 27, 47, 8, 3, 27, 8, 82]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>It</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>PRON</td>\n",
       "      <td>1</td>\n",
       "      <td>[16, 90]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>'s</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>AUX</td>\n",
       "      <td>2</td>\n",
       "      <td>[23, 41]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>DET</td>\n",
       "      <td>3</td>\n",
       "      <td>[90, 4, 35]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>view</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>0</td>\n",
       "      <td>[9, 81, 35, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_num      token  ... pos_indices                          char_list\n",
       "0             0  @paulwalk  ...           0  [24, 56, 27, 47, 8, 3, 27, 8, 82]\n",
       "1             0         It  ...           1                           [16, 90]\n",
       "2             0         's  ...           2                           [23, 41]\n",
       "3             0        the  ...           3                        [90, 4, 35]\n",
       "4             0       view  ...           0                     [9, 81, 35, 3]\n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 279,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use sequence number as the index and apply pandas explode to all other columns\n",
    "train_back = train_seqs.set_index('sequence_num').apply(pd.Series.explode).reset_index()\n",
    "train_back.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yO5S8ChZBfTm",
    "outputId": "51b93ba8-987d-4aa3-d6f2-351ff21e1eda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest chars in the training set is 121 tokens long\n"
     ]
    }
   ],
   "source": [
    "def find_longest_chars(txt,longest_seq):\n",
    "  '''find the longest sequence in the dataframe'''\n",
    "  for i in txt.index:\n",
    "    seqlen = np.max(list(map(lambda x : len(x), (txt['char_list'][i]))))\n",
    "    if seqlen > longest_seq:  # update high water mark if new longest sequence encountered\n",
    "      longest_seq = seqlen\n",
    "  return longest_seq\n",
    "\n",
    "\n",
    "train_longest_char = find_longest_chars(train_seqs,0)\n",
    "print('The longest chars in the training set is %i tokens long' % train_longest_char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kLrK7NyRz59_",
    "outputId": "7b025a58-b718-47e9-8b57-066de61e4b0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest sequence in the training set is 41 tokens long\n"
     ]
    }
   ],
   "source": [
    "def find_longest_sequence(txt,longest_seq):\n",
    "  '''find the longest sequence in the dataframe'''\n",
    "  for i in txt.index:\n",
    "    seqlen = len(txt['token'][i])\n",
    "    if seqlen > longest_seq:  # update high water mark if new longest sequence encountered\n",
    "      longest_seq = seqlen\n",
    "  return longest_seq\n",
    "\n",
    "train_longest = find_longest_sequence(train_seqs,0)\n",
    "print('The longest sequence in the training set is %i tokens long' % train_longest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pEqW_vMBz6Bp",
    "outputId": "a5954dd4-2c78-4c82-a1af-a27917caca01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest sequence in the dev set is 82 tokens long\n",
      "The longest char in the dev set is 66 tokens long\n",
      "The longest sequence in the test set is 105 tokens long\n",
      "The longest char in the test set is 195 tokens long\n"
     ]
    }
   ],
   "source": [
    "# the dev set\n",
    "wnutdev = 'https://storage.googleapis.com/wnut-2017_ner-shared-task/wnut17dev_clean_tagged.txt'\n",
    "dev = pd.read_table(wnutdev, header=None, names=['token', 'label', 'bio_only', 'upos'])\n",
    "dev_copy = extract_features(dev)\n",
    "dev_seqs = tokens2sequences(dev_copy)\n",
    "dev_longest = find_longest_sequence(dev_seqs,0)\n",
    "print('The longest sequence in the dev set is %i tokens long' % dev_longest)\n",
    "\n",
    "dev_longest_char = find_longest_chars(dev_seqs,0)\n",
    "print('The longest char in the dev set is %i tokens long' % dev_longest_char)\n",
    "\n",
    "# the test set\n",
    "wnuttest = 'https://storage.googleapis.com/wnut-2017_ner-shared-task/wnut17test_clean_tagged.txt'\n",
    "test = pd.read_table(wnuttest, header=None, names=['token', 'upos'])\n",
    "test_copy = extract_features(test, True)\n",
    "test_seqs = tokens2sequences(test_copy, True)\n",
    "test_longest = find_longest_sequence(test_seqs,0)\n",
    "print('The longest sequence in the test set is %i tokens long' % test_longest)\n",
    "test_longest_char = find_longest_chars(test_seqs,0)\n",
    "print('The longest char in the test set is %i tokens long' % test_longest_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7eoJU9UeMT9q"
   },
   "outputs": [],
   "source": [
    "# def padd_char(seq):\n",
    "#   X_char = []\n",
    "#   for item in seq[\"char_list\"]:\n",
    "#      sent_seq = []\n",
    "#      for i in range(seq_length):\n",
    "#           word_seq = []\n",
    "#           for j in range(char_seq_length):\n",
    "#               try:\n",
    "#                   word_seq.append(item[j])\n",
    "#               except:\n",
    "#                   word_seq.append(char_padtok)\n",
    "#           sent_seq.append(word_seq)\n",
    "#      X_char.append(np.array(sent_seq))\n",
    "#   return X_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FDxSd2zaMs7j"
   },
   "outputs": [],
   "source": [
    "def padd_char(seq):\n",
    "  temp_char_seqs_padded = []\n",
    "  for item in seq[\"char_list\"]:\n",
    "    temp_pad = pad_sequences(item, maxlen=char_seq_length,\n",
    "                                  dtype='int32', padding='post', truncating='post', value=char_padtok)\n",
    "  \n",
    "    a = temp_pad\n",
    "    b = [[char_padtok for i in range(char_seq_length)] for _ in range(0, seq_length - len(temp_pad))]\n",
    "    c = np.concatenate((a, b))\n",
    "    # print(len(c))\n",
    "    temp_char_seqs_padded.append(c)\n",
    "  # print(len(temp_char_seqs_padded))\n",
    "  return temp_char_seqs_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "soufxysdz6E7",
    "outputId": "b568ae5f-7edd-4691-d677-995b0cbfc2b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The padding token index is 14802\n",
      "Example of padded token sequence:\n",
      "[   26    27    28    29    30    31    32    10    33    34    35    36\n",
      "    13    37    38 14802 14802 14802 14802 14802 14802 14802 14802 14802\n",
      " 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802\n",
      " 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802\n",
      " 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802\n",
      " 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802\n",
      " 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802\n",
      " 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802 14802\n",
      " 14802 14802 14802 14802 14802 14802 14802 14802 14802]\n",
      "Example of padded pos sequence:\n",
      "[ 4  9  9  8  9  0  0  4  9  9  4  9  8  6  6 19 19 19 19 19 19 19 19 19\n",
      " 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19\n",
      " 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19\n",
      " 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19 19\n",
      " 19 19 19 19 19 19 19 19 19]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# set maximum sequence length\n",
    "seq_length = test_longest\n",
    "# char_seq_length = test_longest_char\n",
    "char_seq_length = 5\n",
    "\n",
    "# a new dummy token index, one more than OOV\n",
    "padtok = oov+1\n",
    "pos_padtok = oov_pos+1\n",
    "char_padtok = oov_char + 1\n",
    "\n",
    "print('The padding token index is %i' % padtok)\n",
    "\n",
    "# use pad_sequences, padding or truncating at the end of the sequence (default is 'pre')\n",
    "train_seqs_padded = pad_sequences(train_seqs['token_indices'].tolist(), maxlen=seq_length,\n",
    "                                  dtype='int32', padding='post', truncating='post', value=padtok)\n",
    "\n",
    "\n",
    "\n",
    "train_pos_seqs_padded = pad_sequences(train_seqs['pos_indices'].tolist(), maxlen=seq_length,\n",
    "                                  dtype='int32', padding='post', truncating='post', value=pos_padtok)\n",
    "\n",
    "\n",
    "\n",
    "# Pad Character Level \n",
    "train_char_seqs_padded = padd_char(train_seqs)\n",
    "\n",
    "# for item in train_seqs[\"char_list\"]:\n",
    "#   temp_pad = pad_sequences(item, maxlen=char_seq_length,\n",
    "#                                   dtype='int32', padding='post', truncating='post', value=char_padtok)\n",
    "  \n",
    "#   a = temp_pad\n",
    "#   b = [[char_padtok for i in range(char_seq_length)] for _ in range(0, seq_length - len(temp_pad))]\n",
    "#   c = np.concatenate((a, b))\n",
    "#   # print(len(c))\n",
    "#   train_char_seqs_padded.append(c)\n",
    "\n",
    "print('Example of padded token sequence:')\n",
    "print(train_seqs_padded[1])\n",
    "\n",
    "\n",
    "print('Example of padded pos sequence:')\n",
    "print(train_pos_seqs_padded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dWVF31ooNGol"
   },
   "outputs": [],
   "source": [
    "assert len(train_char_seqs_padded) == len(train_seqs_padded)\n",
    "for item in train_char_seqs_padded:\n",
    "  assert len(item) == len(train_seqs_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U1Vt4R-Gz6Ho",
    "outputId": "a9898038-abb1-4c1b-b519-3e8e2201183b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of padded label sequence and one-hot encoding (first 10 tokens):\n",
      "sequence_num                                                     1\n",
      "token            [From, Green, Newsfeed, :, AHFA, extends, dead...\n",
      "bio_only         [2.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0, 2.0, 2.0, ...\n",
      "token_indices    [26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 10....\n",
      "upos             [ADP, PROPN, PROPN, PUNCT, PROPN, NOUN, NOUN, ...\n",
      "pos_indices      [4.0, 9.0, 9.0, 8.0, 9.0, 0.0, 0.0, 4.0, 9.0, ...\n",
      "char_list        [[68, 39, 21, 84], [36, 39, 35, 35, 61], [69, ...\n",
      "Name: 1, dtype: object\n",
      "Length of input sequence: 105\n",
      "Length of label sequence: 105\n",
      "[2 2 2 2 0 2 2 2 2 2 2]\n",
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# get lists of named entity labels, padded with a null label (=3)\n",
    "padlab = 3\n",
    "train_labs_padded = pad_sequences(train_seqs['bio_only'].tolist(), maxlen=seq_length,\n",
    "                                  dtype='int32', padding='post', truncating='post', value=padlab)\n",
    "\n",
    "# convert those labels to one-hot encoding\n",
    "n_labs = 4  # we have 3 labels: B, I, O (0, 1, 2) + the pad label 3\n",
    "train_labs_onehot = [to_categorical(i, num_classes=n_labs) for i in train_labs_padded]\n",
    "\n",
    "# follow the print outputs below to see how the labels are transformed\n",
    "print('Example of padded label sequence and one-hot encoding (first 10 tokens):')\n",
    "print(train_seqs.loc[1])\n",
    "print('Length of input sequence: %i' % len(train_labs_padded[1]))\n",
    "print('Length of label sequence: %i' % len(train_labs_onehot[1]))\n",
    "print(train_labs_padded[1][:11])\n",
    "print(train_labs_onehot[1][:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7vol4FFhz6Kb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S6yrwKjuz6M-",
    "outputId": "540ead20-7093-4274-cedd-57847fcdd767"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev set padded label sequence and one-hot encoding (first 10 tokens):\n",
      "sequence_num                                                     2\n",
      "token            [All, I, ', ve, been, doing, is, BINGE, watchi...\n",
      "bio_only         [2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...\n",
      "token_indices    [405.0, 7.0, 573.0, 12927.0, 90.0, 848.0, 52.0...\n",
      "upos             [DET, PRON, PUNCT, NOUN, AUX, VERB, AUX, PROPN...\n",
      "pos_indices      [3.0, 1.0, 8.0, 0.0, 2.0, 14.0, 2.0, 9.0, 14.0...\n",
      "char_list        [[32, 8, 8], [16], [23], [9, 35], [79, 35, 35,...\n",
      "Name: 2, dtype: object\n",
      "Length of input sequence: 105\n",
      "Length of label sequence: 105\n",
      "[2 2 2 2 2 2 2 2 2 0 1]\n",
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Prepare Dev Set\n",
    "# now process the dev set in the same way: padding the tokens & labels, and one-hot encoding the labels\n",
    "dev_seqs_padded = pad_sequences(dev_seqs['token_indices'].tolist(), maxlen=seq_length,\n",
    "                                dtype='int32', padding='post', truncating='post', value=padtok)\n",
    "dev_labs_padded = pad_sequences(dev_seqs['bio_only'].tolist(), maxlen=seq_length,\n",
    "                                dtype='int32', padding='post', truncating='post', value=padlab)\n",
    "dev_labs_onehot = [to_categorical(i, num_classes=n_labs) for i in dev_labs_padded]\n",
    "\n",
    "dev_pos_seqs_padded = pad_sequences(dev_seqs['pos_indices'].tolist(), maxlen=seq_length,\n",
    "                                  dtype='int32', padding='post', truncating='post', value=pos_padtok)\n",
    "\n",
    "dev_char_seqs_padded = padd_char(dev_seqs)\n",
    "\n",
    "\n",
    "print('Dev set padded label sequence and one-hot encoding (first 10 tokens):')\n",
    "print(dev_seqs.loc[2])\n",
    "print('Length of input sequence: %i' % len(dev_labs_padded[1]))\n",
    "print('Length of label sequence: %i' % len(dev_labs_onehot[1]))\n",
    "print(dev_labs_padded[2][:11])\n",
    "print(dev_labs_onehot[2][:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b0FzHDB_z6Pl"
   },
   "outputs": [],
   "source": [
    "assert len(dev_char_seqs_padded) == len(dev_pos_seqs_padded)\n",
    "for item in dev_char_seqs_padded:\n",
    "  assert len(item) == len(dev_pos_seqs_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ij2J13sI6035",
    "outputId": "9dbcc0c6-b2f3-466a-f0fd-9f9c42677209"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence dimensions (n.docs, seq.length):\n",
      "(3375, 105)\n",
      "Input pos dimensions (n.docs, seq.length):\n",
      "(3375, 105)\n",
      "Input char dimensions (n.docs, seq.length):\n",
      "(3375, 105, 5)\n",
      "Label dimensions (n.docs, seq.length, one-hot encoding of 4 NER labels):\n",
      "(3375, 105, 4)\n",
      "**Defining a neural network**\n",
      "Model: \"functional_71\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "char_input3 (InputLayer)        [(None, 105, 5)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tok_input1 (InputLayer)         [(None, 105)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pos_input2 (InputLayer)         [(None, 105)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_90 (TimeDistri (None, 105, 5, 128)  12032       char_input3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "embedding_96 (Embedding)        (None, 105, 128)     1894784     tok_input1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_97 (Embedding)        (None, 105, 128)     2560        pos_input2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_91 (TimeDistri (None, 105, 100)     71600       time_distributed_90[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 105, 356)     0           embedding_96[0][0]               \n",
      "                                                                 embedding_97[0][0]               \n",
      "                                                                 time_distributed_91[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_61 (Bidirectional (None, 105, 100)     162800      concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 105, 100)     0           bidirectional_61[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_92 (TimeDistri (None, 105, 4)       404         dropout_30[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,144,180\n",
      "Trainable params: 2,144,180\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load Keras and TensorFlow\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "# from keras_contrib.layers import CRF\n",
    "\n",
    "# prepare sequences and labels as numpy arrays, check dimensions\n",
    "X = np.array(train_seqs_padded)\n",
    "y = np.array(train_labs_onehot)\n",
    "X_pos = np.array(train_pos_seqs_padded)\n",
    "X_char = np.array(train_char_seqs_padded)\n",
    "\n",
    "print('Input sequence dimensions (n.docs, seq.length):')\n",
    "print(X.shape)\n",
    "print('Input pos dimensions (n.docs, seq.length):')\n",
    "print(X_pos.shape)\n",
    "print('Input char dimensions (n.docs, seq.length):')\n",
    "print(X_char.shape)\n",
    "print('Label dimensions (n.docs, seq.length, one-hot encoding of 4 NER labels):')\n",
    "print(y.shape)\n",
    "\n",
    "# our final vocab size is the padding token + 1 (OR length of vocab + OOV + PAD)\n",
    "vocab_size = padtok+1\n",
    "assert (vocab_size==len(token_vocab)+2)\n",
    "\n",
    "\n",
    "# Validate the index of pos tag.\n",
    "\n",
    "pos_size = pos_padtok + 1\n",
    "assert (pos_size==len(pos_vocab)+2)\n",
    "\n",
    "char_size = char_padtok + 1\n",
    "assert (char_size==len(char_vocab)+2)\n",
    "\n",
    "embed_size = 128  # try an embedding size of 128 (could tune this)\n",
    "\n",
    "#Â list of metrics to use: true & false positives, negatives, accuracy, precision, recall, area under the curve\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "# our model has the option for an label prediction bias, it's sequential, starts with an embedding layer, then bi-LSTM,\n",
    "# a dropout layer follows for regularisation, and a dense final layer with softmax activation to output class probabilities\n",
    "# we compile with the Adam optimizer at a low learning rate, use categorical cross-entropy as our loss function\n",
    "def make_model(metrics = METRICS, output_bias=None):\n",
    "  if output_bias is not None:\n",
    "    output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "\n",
    "  tok_input1 = keras.layers.Input(shape=(seq_length,), dtype='int32', name='tok_input1')\n",
    "  pos_input2 = keras.layers.Input(shape=(seq_length,), dtype='int32', name='pos_input2')\n",
    "  # (\"CHAR INPUT\")\n",
    "  # print(char_input3)\n",
    "\n",
    "  # Character Level Model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  # char_in = keras.layers.Input(shape=(seq_length,char_seq_length,), dtype='int32', name='char_in')\n",
    "  char_input3 = keras.layers.Input(shape=(seq_length,char_seq_length), dtype='int32', name='char_input3')\n",
    "  emb_char = keras.layers.TimeDistributed(keras.layers.Embedding(output_dim=embed_size, input_dim=char_size, input_length=5,  mask_zero=True, trainable=True))(char_input3)\n",
    "  char_enc = keras.layers.TimeDistributed(keras.layers.Bidirectional(keras.layers.LSTM(units=50, return_sequences=False, dropout=0.2, recurrent_dropout=0.2)))(emb_char)\n",
    "\n",
    "\n",
    "\n",
    "  # char_output = char_x_lstm\n",
    "  # char_model = tf.keras.Model(inputs=char_in, outputs=char_output)\n",
    "\n",
    "# input_inner = Input(shape=(4,), name='input_inner')\n",
    "# output_inner = Dense(3, name='inner_dense')(input_inner)\n",
    "# inner_model = Model(inputs=input_inner, outputs=output_inner)\n",
    "\n",
    "\n",
    "  # x3 = char_model(char_input3)\n",
    "\n",
    "  x1 = keras.layers.Embedding(output_dim=embed_size, input_dim=vocab_size,  input_length=seq_length,  mask_zero=True, trainable=True)(tok_input1)\n",
    "  x2 = keras.layers.Embedding(output_dim=embed_size, input_dim=pos_size,  input_length=seq_length, mask_zero=True, trainable=True)(pos_input2)\n",
    "  \n",
    "  # print(\":D\")\n",
    "  # print(tok_input1)\n",
    "  \n",
    "\n",
    "  x_cancat = keras.layers.concatenate([x1, x2, char_enc ])\n",
    "  # x_cancat = keras.layers.concatenate([x1, x2])\n",
    "\n",
    "  x_lstm = keras.layers.Bidirectional(keras.layers.LSTM(units=50, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))(x_cancat)\n",
    "  x_drop = keras.layers.Dropout(0.5)(x_lstm)\n",
    "  main_output = keras.layers.TimeDistributed(keras.layers.Dense(n_labs, activation='softmax', bias_initializer=output_bias))(x_drop)\n",
    " # model = keras.Sequential()\n",
    " # model.add(keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_size, input_length=seq_length, mask_zero=True, trainable=True))\n",
    "# model.add(keras.layers.Bidirectional(keras.layers.LSTM(units=50, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)))\n",
    "#  model.add(keras.layers.Dropout(0.5))\n",
    "#  model.add(keras.layers.TimeDistributed(keras.layers.Dense(n_labs, activation='softmax', bias_initializer=output_bias)))\n",
    "  # crf = CRF(4)  # CRF layer, n_tags+1(PAD)\n",
    "  # main_output = crf(main_output)  # output\n",
    "\n",
    "  model = keras.models.Model(inputs=[tok_input1, pos_input2, char_input3], outputs= main_output)\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(lr=1e-3), loss=keras.losses.CategoricalCrossentropy(), metrics=metrics)\n",
    "  return model\n",
    "\n",
    "# early stopping criteria based on area under the curve: will stop if no improvement after 10 epochs\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_auc', verbose=1, patience=10, mode='max', restore_best_weights=True)\n",
    "\n",
    "# the number of training epochs we'll use, and the batch size (how many texts are input at once)\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print('**Defining a neural network**')\n",
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ib8KD0EuMOBQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6J7R-P4560oT",
    "outputId": "63529675-902f-42e7-dbc5-840f6d602786"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2489\n"
     ]
    }
   ],
   "source": [
    "# evaluate our initial model\n",
    "\n",
    "\n",
    "results = model.evaluate([X,X_pos,X_char], y, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dyY9ldZP-Ocm",
    "outputId": "6413a628-f2d0-444a-c17c-f9b7cc744ce9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 292139, 2: 59095, 0: 1964, 1: 1177})\n",
      "354375\n",
      "Initial bias:\n",
      "[0.005542151675485009, 0.0033213403880070548, 0.1667583774250441, 0.8243781305114638]\n",
      "Loss: 0.9495\n"
     ]
    }
   ],
   "source": [
    "# figure out the label distribution in our fixed-length texts\n",
    "from collections import Counter\n",
    "\n",
    "all_labs = [l for lab in train_labs_padded for l in lab]\n",
    "label_count = Counter(all_labs)\n",
    "total_labs = len(all_labs)\n",
    "print(label_count)\n",
    "print(total_labs)\n",
    "\n",
    "# use this to define an initial model bias\n",
    "initial_bias=[(label_count[0]/total_labs), (label_count[1]/total_labs),\n",
    "              (label_count[2]/total_labs), (label_count[3]/total_labs)]\n",
    "print('Initial bias:')\n",
    "print(initial_bias)\n",
    "\n",
    "# pass the bias to the model and re-evaluate\n",
    "model = make_model(output_bias=initial_bias)\n",
    "results = model.evaluate([X,X_pos,X_char], y, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHhUQoif60Tt"
   },
   "outputs": [],
   "source": [
    "# # prepare the dev sequences and labels as numpy arrays\n",
    "dev_X = np.array(dev_seqs_padded)\n",
    "dev_X_pos = np.array(dev_pos_seqs_padded)\n",
    "dev_X_char = np.array(dev_char_seqs_padded)\n",
    "dev_y = np.array(dev_labs_onehot)\n",
    "\n",
    "\n",
    "# # re-initiate model with bias\n",
    "# model = make_model(output_bias=initial_bias)\n",
    "\n",
    "# # and fit...\n",
    "# model.fit([X,X_pos] , y, batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks = [early_stopping], validation_data=([dev_X, dev_X_pos],dev_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VHkx8CI360HW"
   },
   "outputs": [],
   "source": [
    "# # use argmax to figure out the class with highest probability per token\n",
    "# preds = np.argmax(model.predict([dev_seqs_padded,dev_pos_seqs_padded]), axis=-1)\n",
    "# flat_preds = [p for pred in preds for p in pred]\n",
    "# print(Counter(flat_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sEaH3IMk6zlo",
    "outputId": "afc129d7-36dc-4096-bd79-a310d29f5614"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial one-hot label encoding:\n",
      "[[0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]]\n",
      "Weighted label encoding:\n",
      "[[0.  0.  0.1 0. ]\n",
      " [0.  0.  0.1 0. ]\n",
      " [0.  0.  0.1 0. ]\n",
      " [0.  0.  0.1 0. ]\n",
      " [1.  0.  0.  0. ]\n",
      " [0.  0.  0.1 0. ]\n",
      " [0.  0.  0.1 0. ]\n",
      " [0.  0.  0.1 0. ]\n",
      " [0.  0.  0.1 0. ]\n",
      " [0.  0.  0.1 0. ]\n",
      " [0.  0.  0.1 0. ]]\n"
     ]
    }
   ],
   "source": [
    "# use deep copy to ensure we aren't updating original values\n",
    "import copy\n",
    "train_weights_onehot = copy.deepcopy(train_labs_onehot)\n",
    "\n",
    "# our first-pass class weights: normal for named entities (0 and 1), down-weighted for non named entities (2 and 3)\n",
    "class_wts = [1,1,.1,.1]\n",
    "\n",
    "# apply our weights to the label lists\n",
    "for i,labs in enumerate(train_weights_onehot):\n",
    "  for j,lablist in enumerate(labs):\n",
    "    lablistaslist = lablist.tolist()\n",
    "    whichismax = lablistaslist.index(max(lablistaslist))\n",
    "    train_weights_onehot[i][j][whichismax] = class_wts[whichismax]\n",
    "\n",
    "# what's this like, before and after?\n",
    "print('Initial one-hot label encoding:')\n",
    "print(train_labs_onehot[1][:11])\n",
    "\n",
    "print('Weighted label encoding:')\n",
    "print(train_weights_onehot[1][:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XOzIYPR0Bow9",
    "outputId": "6d0cca9e-efba-4a09-ae69-6beb59c2dc2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label dimensions (n.docs, seq.length, one-hot encoding of 4 NER labels):\n",
      "(3375, 105, 4)\n",
      "Epoch 1/100\n",
      "106/106 [==============================] - 132s 1s/step - loss: 0.0252 - tp: 314321.0000 - fp: 5649.0000 - tn: 3074124.0000 - fn: 712270.0000 - accuracy: 0.7487 - precision: 0.9823 - recall: 0.3062 - auc: 0.9429 - val_loss: 0.0337 - val_tp: 100363.0000 - val_fp: 495.0000 - val_tn: 304086.0000 - val_fn: 1164.0000 - val_accuracy: 0.9959 - val_precision: 0.9951 - val_recall: 0.9885 - val_auc: 0.9998\n",
      "Epoch 2/100\n",
      "106/106 [==============================] - 130s 1s/step - loss: 0.0110 - tp: 336198.0000 - fp: 2683.0000 - tn: 1023908.0000 - fn: 5999.0000 - accuracy: 0.7489 - precision: 0.9921 - recall: 0.9825 - auc: 0.9997 - val_loss: 0.0239 - val_tp: 100616.0000 - val_fp: 570.0000 - val_tn: 304011.0000 - val_fn: 911.0000 - val_accuracy: 0.9964 - val_precision: 0.9944 - val_recall: 0.9910 - val_auc: 0.9999\n",
      "Epoch 3/100\n",
      "106/106 [==============================] - 131s 1s/step - loss: 0.0071 - tp: 338511.0000 - fp: 2416.0000 - tn: 1024175.0000 - fn: 3686.0000 - accuracy: 0.7496 - precision: 0.9929 - recall: 0.9892 - auc: 0.9999 - val_loss: 0.0209 - val_tp: 100745.0000 - val_fp: 629.0000 - val_tn: 303952.0000 - val_fn: 782.0000 - val_accuracy: 0.9965 - val_precision: 0.9938 - val_recall: 0.9923 - val_auc: 0.9998\n",
      "Epoch 4/100\n",
      "106/106 [==============================] - 133s 1s/step - loss: 0.0044 - tp: 340220.0000 - fp: 1425.0000 - tn: 1025166.0000 - fn: 1977.0000 - accuracy: 0.7506 - precision: 0.9958 - recall: 0.9942 - auc: 0.9999 - val_loss: 0.0215 - val_tp: 100725.0000 - val_fp: 649.0000 - val_tn: 303932.0000 - val_fn: 802.0000 - val_accuracy: 0.9964 - val_precision: 0.9936 - val_recall: 0.9921 - val_auc: 0.9997\n",
      "Epoch 5/100\n",
      "106/106 [==============================] - 130s 1s/step - loss: 0.0028 - tp: 340967.0000 - fp: 958.0000 - tn: 1025633.0000 - fn: 1230.0000 - accuracy: 0.7510 - precision: 0.9972 - recall: 0.9964 - auc: 0.9999 - val_loss: 0.0250 - val_tp: 100578.0000 - val_fp: 779.0000 - val_tn: 303802.0000 - val_fn: 949.0000 - val_accuracy: 0.9957 - val_precision: 0.9923 - val_recall: 0.9907 - val_auc: 0.9996\n",
      "Epoch 6/100\n",
      "106/106 [==============================] - 131s 1s/step - loss: 0.0020 - tp: 341284.0000 - fp: 736.0000 - tn: 1025855.0000 - fn: 913.0000 - accuracy: 0.7513 - precision: 0.9978 - recall: 0.9973 - auc: 0.9999 - val_loss: 0.0248 - val_tp: 100655.0000 - val_fp: 742.0000 - val_tn: 303839.0000 - val_fn: 872.0000 - val_accuracy: 0.9960 - val_precision: 0.9927 - val_recall: 0.9914 - val_auc: 0.9995\n",
      "Epoch 7/100\n",
      "106/106 [==============================] - 131s 1s/step - loss: 0.0015 - tp: 341411.0000 - fp: 661.0000 - tn: 1025930.0000 - fn: 786.0000 - accuracy: 0.7514 - precision: 0.9981 - recall: 0.9977 - auc: 0.9999 - val_loss: 0.0243 - val_tp: 100731.0000 - val_fp: 706.0000 - val_tn: 303875.0000 - val_fn: 796.0000 - val_accuracy: 0.9963 - val_precision: 0.9930 - val_recall: 0.9922 - val_auc: 0.9993\n",
      "Epoch 8/100\n",
      "106/106 [==============================] - 132s 1s/step - loss: 0.0011 - tp: 341594.0000 - fp: 519.0000 - tn: 1026072.0000 - fn: 603.0000 - accuracy: 0.7515 - precision: 0.9985 - recall: 0.9982 - auc: 0.9999 - val_loss: 0.0269 - val_tp: 100661.0000 - val_fp: 763.0000 - val_tn: 303818.0000 - val_fn: 866.0000 - val_accuracy: 0.9960 - val_precision: 0.9925 - val_recall: 0.9915 - val_auc: 0.9993\n",
      "Epoch 9/100\n",
      "106/106 [==============================] - 130s 1s/step - loss: 9.2746e-04 - tp: 341678.0000 - fp: 443.0000 - tn: 1026148.0000 - fn: 519.0000 - accuracy: 0.7516 - precision: 0.9987 - recall: 0.9985 - auc: 0.9999 - val_loss: 0.0269 - val_tp: 100792.0000 - val_fp: 680.0000 - val_tn: 303901.0000 - val_fn: 735.0000 - val_accuracy: 0.9965 - val_precision: 0.9933 - val_recall: 0.9928 - val_auc: 0.9990\n",
      "Epoch 10/100\n",
      "106/106 [==============================] - 129s 1s/step - loss: 7.2784e-04 - tp: 341765.0000 - fp: 387.0000 - tn: 1026204.0000 - fn: 432.0000 - accuracy: 0.7516 - precision: 0.9989 - recall: 0.9987 - auc: 0.9999 - val_loss: 0.0272 - val_tp: 100751.0000 - val_fp: 724.0000 - val_tn: 303857.0000 - val_fn: 776.0000 - val_accuracy: 0.9963 - val_precision: 0.9929 - val_recall: 0.9924 - val_auc: 0.9990\n",
      "Epoch 11/100\n",
      "106/106 [==============================] - 130s 1s/step - loss: 6.9711e-04 - tp: 341807.0000 - fp: 353.0000 - tn: 1026238.0000 - fn: 390.0000 - accuracy: 0.7516 - precision: 0.9990 - recall: 0.9989 - auc: 1.0000 - val_loss: 0.0290 - val_tp: 100811.0000 - val_fp: 674.0000 - val_tn: 303907.0000 - val_fn: 716.0000 - val_accuracy: 0.9966 - val_precision: 0.9934 - val_recall: 0.9929 - val_auc: 0.9988\n",
      "Epoch 12/100\n",
      "106/106 [==============================] - ETA: 0s - loss: 6.1545e-04 - tp: 341834.0000 - fp: 335.0000 - tn: 1026256.0000 - fn: 363.0000 - accuracy: 0.7516 - precision: 0.9990 - recall: 0.9989 - auc: 1.0000Restoring model weights from the end of the best epoch.\n",
      "106/106 [==============================] - 130s 1s/step - loss: 6.1545e-04 - tp: 341834.0000 - fp: 335.0000 - tn: 1026256.0000 - fn: 363.0000 - accuracy: 0.7516 - precision: 0.9990 - recall: 0.9989 - auc: 1.0000 - val_loss: 0.0304 - val_tp: 100709.0000 - val_fp: 766.0000 - val_tn: 303815.0000 - val_fn: 818.0000 - val_accuracy: 0.9961 - val_precision: 0.9925 - val_recall: 0.9919 - val_auc: 0.9988\n",
      "Epoch 00012: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f04bf27b470>"
      ]
     },
     "execution_count": 296,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAINTRAIN\n",
    "# now try the weighted one-hot encoding\n",
    "y = np.array(train_weights_onehot)\n",
    "print('Label dimensions (n.docs, seq.length, one-hot encoding of 4 NER labels):')\n",
    "print(np.shape(y))\n",
    "\n",
    "\n",
    "\n",
    "model2 = make_model(output_bias=initial_bias)\n",
    "model2.fit([X,X_pos,X_char], y, batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks = [early_stopping], validation_data=([dev_X,dev_X_pos,dev_X_char], dev_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-qV6xzHQUXPh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WPRD2te1UXg7"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yZfsztrYBonv",
    "outputId": "c37ff928-190c-4be6-e9a8-4051f71a9b87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 91655, 2: 11662, 0: 850, 1: 98})\n"
     ]
    }
   ],
   "source": [
    "preds = np.argmax(model2.predict([dev_X,dev_X_pos,dev_X_char]), axis=-1)\n",
    "flat_preds = [p for pred in preds for p in pred]\n",
    "print(Counter(flat_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V_WP3HliGHe-"
   },
   "outputs": [],
   "source": [
    "# corrected_preds = []\n",
    "\n",
    "# for item in (preds):\n",
    "#   preds_temp = item\n",
    "\n",
    "#   if preds_temp[0] == 1:\n",
    "#       preds_temp[0] = 0\n",
    "    \n",
    "#   for i in range(1,len(preds_temp)):\n",
    "#       if preds_temp[i] == 1:\n",
    "#         if preds_temp[i-1] == 2 :\n",
    "#           preds_temp[i] = 0\n",
    "\n",
    "#   corrected_preds.append(preds_temp)\n",
    "  \n",
    "#   preds = corrected_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "id": "8XRBaoq8Bodk",
    "outputId": "258dd80c-cd6f-4c28-94b8-26affe94a437"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_num</th>\n",
       "      <th>token</th>\n",
       "      <th>bio_only</th>\n",
       "      <th>token_indices</th>\n",
       "      <th>upos</th>\n",
       "      <th>pos_indices</th>\n",
       "      <th>char_list</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[Stabilized, approach, or, not, ?, That, Â´, s,...</td>\n",
       "      <td>[2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, ...</td>\n",
       "      <td>[14801.0, 10361.0, 414.0, 556.0, 131.0, 1740.0...</td>\n",
       "      <td>[PROPN, NOUN, CCONJ, PART, PUNCT, PRON, SYM, P...</td>\n",
       "      <td>[9.0, 0.0, 16.0, 15.0, 8.0, 1.0, 10.0, 15.0, 1...</td>\n",
       "      <td>[[34, 90, 27, 79, 81, 8, 81, 62, 35, 37], [27,...</td>\n",
       "      <td>[0, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_num  ...                            prediction\n",
       "0             0  ...  [0, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
       "\n",
       "[1 rows x 8 columns]"
      ]
     },
     "execution_count": 299,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_seqs['prediction'] = ''\n",
    "\n",
    "# for each text: get original sequence length and trim predictions accordingly\n",
    "# (_trim_ because we know that our seq length is longer than the longest seq in dev)\n",
    "for i in dev_seqs.index:\n",
    "  this_seq_length = len(dev_seqs['token'][i])\n",
    "  dev_seqs['prediction'][i] = preds[i][:this_seq_length].astype(int)\n",
    "\n",
    "dev_seqs.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "gHbQe6TiBoLP",
    "outputId": "ee19db2e-2992-4413-bee3-ffd98d1c80cf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_num</th>\n",
       "      <th>token</th>\n",
       "      <th>bio_only</th>\n",
       "      <th>token_indices</th>\n",
       "      <th>upos</th>\n",
       "      <th>pos_indices</th>\n",
       "      <th>char_list</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Stabilized</td>\n",
       "      <td>2</td>\n",
       "      <td>14801</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>9</td>\n",
       "      <td>[34, 90, 27, 79, 81, 8, 81, 62, 35, 37]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_num       token  ...                                char_list prediction\n",
       "0             0  Stabilized  ...  [34, 90, 27, 79, 81, 8, 81, 62, 35, 37]          0\n",
       "\n",
       "[1 rows x 8 columns]"
      ]
     },
     "execution_count": 300,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_long = dev_seqs.set_index('sequence_num').apply(pd.Series.explode).reset_index()\n",
    "dev_long.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "waI5lvpDFrC8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LrIWppkaFB5P",
    "outputId": "05a4f5de-c00f-4d3a-b489-c47700ec7ace"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O    14434\n",
       "B      850\n",
       "I       98\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 301,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-using the BIO integer-to-character function from last time\n",
    "def reverse_bio(ind):\n",
    "  bio = 'O'  # for any pad=3 predictions\n",
    "  if ind==0:\n",
    "    bio = 'B'\n",
    "  elif ind==1:\n",
    "    bio = 'I'\n",
    "  elif ind==2:\n",
    "    bio = 'O'\n",
    "  return bio\n",
    "\n",
    "bio_labs = [reverse_bio(b) for b in dev_long['bio_only']]\n",
    "dev_long['bio_only'] = bio_labs\n",
    "pred_labs = [reverse_bio(b) for b in dev_long['prediction']]\n",
    "dev_long['prediction'] = pred_labs\n",
    "\n",
    "dev_long.head()\n",
    "dev_long.prediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eqloxUGvFmzc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-JkZnTAYc9t"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FkYK7R4HFBr7",
    "outputId": "a8ef206a-2a32-4a04-fa02-25df619b4a88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of TP and FP = 728\n",
      "Sum of TP and FN = 787\n",
      "True positives = 359, False positives = 369, False negatives = 428\n",
      "Precision = 0.493, Recall = 0.456, F1 = 0.474 (max=1)\n"
     ]
    }
   ],
   "source": [
    "def wnut_evaluate(txt):\n",
    "  '''row by row entity evaluation: we evaluate by whole named entities'''\n",
    "  tp = 0; fp = 0; fn = 0\n",
    "  in_entity = 0\n",
    "  for i in txt.index:\n",
    "    if txt['prediction'][i]=='B' and txt['bio_only'][i]=='B':\n",
    "      if in_entity==1:  # if there's a preceding named entity which didn't have intervening O...\n",
    "        tp += 1  # count a true positive\n",
    "      in_entity = 1  # start tracking this entity (don't count it until we know full span of entity)\n",
    "    elif txt['prediction'][i]=='B':\n",
    "      fp += 1  # if not a B in gold annotations, it's a false positive\n",
    "      in_entity = 0\n",
    "    elif txt['prediction'][i]=='I' and txt['bio_only'][i]=='I':\n",
    "      next  # correct entity continuation: do nothing\n",
    "    elif txt['prediction'][i]=='I' and txt['bio_only'][i]=='B':\n",
    "      fn += 1  # if a new entity should have begun, it's a false negative\n",
    "      in_entity = 0\n",
    "    elif txt['prediction'][i]=='I':  # if gold is O...\n",
    "      if in_entity==1:  # and if tracking an entity, then the span is too long\n",
    "        fp += 1  # it's a false positive\n",
    "      in_entity = 0\n",
    "    elif txt['prediction'][i]=='O':\n",
    "      if txt['bio_only'][i]=='B':\n",
    "        fn += 1  # false negative if there's B in gold but no predicted B\n",
    "        if in_entity==1:  # also check if there was a named entity in progress\n",
    "          tp += 1  # count a true positive\n",
    "      elif txt['bio_only'][i]=='I':\n",
    "        if in_entity==1:  # if this should have been a continued named entity, the span is too short\n",
    "          fn += 1  # count a false negative\n",
    "      elif txt['bio_only'][i]=='O':\n",
    "        if in_entity==1:  # if a named entity has ended in right place\n",
    "          tp += 1  # count a true positive\n",
    "      in_entity = 0\n",
    "\n",
    "  if in_entity==1:  # catch any final named entity\n",
    "    tp += 1\n",
    "\n",
    "  print('Sum of TP and FP = %i' % (tp+fp))\n",
    "  print('Sum of TP and FN = %i' % (tp+fn))\n",
    "  print('True positives = %i, False positives = %i, False negatives = %i' % (tp, fp, fn))\n",
    "  prec = tp / (tp+fp)\n",
    "  rec = tp / (tp+fn)\n",
    "  f1 = (2*(prec*rec)) / (prec+rec)\n",
    "  print('Precision = %.3f, Recall = %.3f, F1 = %.3f (max=1)' % (prec, rec, f1))\n",
    " \n",
    "wnut_evaluate(dev_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQzU3ngQFBgW"
   },
   "outputs": [],
   "source": [
    "dev_long.to_csv('FullChar_POS.txt', sep='\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ycwMJhUSFJlO",
    "outputId": "492db2a1-4c67-4d84-ada6-275627631042"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 3.7944008e-02 -4.0139817e-02  4.3443356e-02 ... -6.0362816e-03\n",
      "    4.3971453e-02  1.3044428e-02]\n",
      "  [-2.5121773e-02 -1.6110610e-02  3.1035293e-02 ... -4.0632892e-02\n",
      "    2.5921497e-02 -1.3672568e-02]\n",
      "  [ 1.9855287e-02 -4.1204166e-02 -4.0947497e-02 ...  4.7824193e-02\n",
      "    2.3099791e-02  6.7340359e-03]\n",
      "  ...\n",
      "  [ 4.0894020e-02 -2.9814554e-02  4.6110000e-02 ...  2.9666200e-03\n",
      "    3.9487209e-02  6.8763010e-03]\n",
      "  [-1.1260174e-02  3.9378885e-02  6.7757480e-03 ... -4.4277050e-02\n",
      "   -2.5374031e-02  2.0289645e-03]\n",
      "  [ 1.3178315e-02  4.4306424e-02  3.3303585e-02 ...  4.4635151e-02\n",
      "    1.7653774e-02  2.0456124e-02]]\n",
      "\n",
      " [[ 4.9144957e-02  3.7639927e-02 -2.0032609e-02 ...  2.3464050e-02\n",
      "    2.9969368e-02  2.8843060e-03]\n",
      "  [-4.3046035e-02 -4.6730280e-02 -3.5760511e-02 ... -2.6661981e-02\n",
      "   -4.5612026e-02  1.9947592e-02]\n",
      "  [ 3.7315082e-02  3.5888802e-02 -3.8528264e-02 ...  2.1984909e-02\n",
      "   -9.0875849e-03  1.5853532e-03]\n",
      "  ...\n",
      "  [ 2.5715325e-02 -2.4869228e-02 -8.0524907e-03 ... -3.9823581e-02\n",
      "    1.3650544e-03 -1.0804962e-02]\n",
      "  [ 7.3790550e-03 -4.0638685e-02  5.2366965e-03 ...  8.9261048e-03\n",
      "   -1.8134881e-02 -3.4380149e-02]\n",
      "  [ 4.5860898e-02  4.7175180e-02  1.2445293e-02 ...  3.4585509e-02\n",
      "    4.2448428e-02 -5.7610385e-03]]\n",
      "\n",
      " [[ 3.2944456e-03  3.0679990e-02  2.0309415e-02 ... -3.0769838e-02\n",
      "   -2.3094535e-02  3.8348686e-02]\n",
      "  [ 1.1318933e-02 -3.5745252e-02 -4.6488561e-02 ... -2.0956509e-03\n",
      "    2.3244727e-02 -1.8746484e-02]\n",
      "  [ 2.6742946e-02  2.8576478e-03 -4.6926029e-03 ... -2.5112843e-02\n",
      "   -4.8404314e-02  2.4492096e-02]\n",
      "  ...\n",
      "  [ 4.6560500e-02  2.0956326e-02 -3.5259642e-02 ... -4.3170989e-02\n",
      "    1.0823749e-02  4.2719070e-02]\n",
      "  [ 4.4974338e-02  2.4321649e-02 -4.3275144e-02 ... -6.0696229e-03\n",
      "    3.8342725e-02 -1.1605073e-02]\n",
      "  [-7.8324191e-03  5.4211617e-03  3.4389976e-02 ... -4.0789664e-02\n",
      "    1.6218986e-02  1.1985525e-03]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 5.0085559e-03  2.3679402e-02 -2.0478858e-02 ...  3.1467650e-02\n",
      "    1.4565539e-02 -3.2969631e-02]\n",
      "  [ 3.0877378e-02  3.6132958e-02  4.9222503e-02 ... -9.0502203e-05\n",
      "    2.4422791e-02  4.2671729e-02]\n",
      "  [ 1.9349288e-02  1.4866922e-02 -7.6575875e-03 ... -1.7469276e-02\n",
      "    2.8731082e-02  2.2267725e-02]\n",
      "  ...\n",
      "  [-2.8655101e-02  4.2827699e-02 -9.0477243e-03 ...  3.7834708e-02\n",
      "   -1.0872342e-02  4.8069980e-02]\n",
      "  [ 3.7884858e-02 -2.9201662e-02  4.1390900e-02 ... -2.8896704e-03\n",
      "    1.3843190e-02 -8.5166469e-03]\n",
      "  [ 1.5482757e-02  2.6280571e-02  8.3779208e-03 ...  1.1939429e-02\n",
      "    2.5414217e-02  4.6723519e-02]]\n",
      "\n",
      " [[ 4.2355169e-02  1.3197772e-03  4.5378637e-02 ... -2.2428263e-02\n",
      "   -2.1886397e-02 -4.1371178e-02]\n",
      "  [-3.8087618e-02  2.9118214e-02  4.9767736e-02 ... -3.9215013e-04\n",
      "   -8.1448443e-03 -2.7493525e-02]\n",
      "  [ 4.0201474e-02  9.9941604e-03  1.7647576e-02 ... -4.3101229e-02\n",
      "   -2.9994417e-02  5.4907314e-03]\n",
      "  ...\n",
      "  [-1.0033034e-02 -4.9671352e-02  3.1512905e-02 ...  4.9155626e-02\n",
      "    2.0271491e-02 -3.2581616e-02]\n",
      "  [-1.0384034e-02 -2.3332095e-02  1.7523739e-02 ... -2.2515392e-02\n",
      "   -3.3944726e-02 -3.1376705e-03]\n",
      "  [ 1.5429128e-02  1.2862969e-02  1.6381685e-02 ...  3.4969959e-02\n",
      "    1.3172124e-02 -2.2321165e-02]]\n",
      "\n",
      " [[ 3.7650708e-02 -4.5080330e-02 -6.5743923e-05 ...  2.0395670e-02\n",
      "   -3.5458803e-03 -1.3723850e-02]\n",
      "  [-1.1439644e-02 -2.7165115e-02 -5.7114847e-03 ...  1.4503788e-02\n",
      "    1.3607990e-02 -4.8952129e-02]\n",
      "  [-4.1321181e-02 -4.5906212e-02  3.9093327e-02 ... -2.2262229e-02\n",
      "   -2.2094322e-02 -3.6545373e-02]\n",
      "  ...\n",
      "  [ 4.8151042e-02  2.3203935e-02  4.2776372e-02 ... -3.3778921e-03\n",
      "    4.8591819e-02  2.8702710e-02]\n",
      "  [-8.9981444e-03  6.4832196e-03 -4.8099376e-02 ... -3.5574447e-02\n",
      "   -3.4224249e-02 -2.6347971e-02]\n",
      "  [ 4.2261470e-02  1.8278148e-02  2.4104182e-02 ... -3.7569858e-02\n",
      "    4.4351224e-02  3.1549048e-02]]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "import numpy as np\n",
    " \n",
    "model = Sequential()\n",
    "model.add(Embedding(1000, 64, input_length=10))\n",
    "# è¾å¥å¤§å°ä¸º(Noneï¼10)ï¼Nnoeæ¯batch_sizeå¤§å°ï¼10ä»£è¡¨æ¯ä¸ä¸ªbatchä¸­æ10æ¡æ ·æ¬\n",
    "# è¾åºå¤§å°ä¸º(None, 10, 64),å¶ä¸­64ä»£è¡¨è¾å¥ä¸­æ¯ä¸ªæ¯æ¡æ ·æ¬è¢«embeddingæäº64ç»´çåé\n",
    " \n",
    "input_array = np.random.randint(1000, size=(32, 10))\n",
    "\n",
    "\n",
    "\n",
    "model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict(input_array)\n",
    "print(output_array)\n",
    "assert output_array.shape == (32, 10, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w4NPFCfWlaJx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E_GwiqibFBUc",
    "outputId": "945e1fbf-f94f-41fd-972a-2a5408145a32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00898102 -0.01233068]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(0)\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(0)\n",
    "\n",
    "\n",
    "data = array([0.1,0.2,0.3]).reshape((1,3,1))\n",
    "inputs1 = Input(shape=(3,1))\n",
    "lstm1,state_h,state_c = LSTM(2,return_sequences=True,return_state=True)(inputs1) #ç¬¬ä¸å±LSTM\n",
    "lstm2 = LSTM(2,return_sequences=False)(lstm1)  #ç¬¬äºå±LSTM\n",
    "model = Model( inputs1,outputs = [lstm2])\n",
    "\n",
    "print(model.predict(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "blCY6spaFAkg"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6uVFTZL3mmVZ",
    "outputId": "df887ca7-2ad6-4191-ec1e-69e7d7c28e15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 600893\n",
      "Total chars: 56\n",
      "Number of sequences: 200285\n"
     ]
    }
   ],
   "source": [
    "path = keras.utils.get_file(\n",
    "    \"nietzsche.txt\", origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\"\n",
    ")\n",
    "with io.open(path, encoding=\"utf-8\") as f:\n",
    "    text = f.read().lower()\n",
    "text = text.replace(\"\\n\", \" \")  # We remove newlines chars for nicer display\n",
    "print(\"Corpus length:\", len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print(\"Total chars:\", len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i : i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print(\"Number of sequences:\", len(sentences))\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hoHMwGHgmmSA",
    "outputId": "dbafc948-5f27-452c-c630-69b24fa5d1c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preface   supposing that truth is a woma\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c-J4FduPmmOc",
    "outputId": "85dc2b7c-1217-4b87-fda0-4d21e9a294f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False],\n",
       "       [False, False, False, ..., False, False, False]])"
      ]
     },
     "execution_count": 309,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iLv5A-TgmmI4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yYGnJLTfml-a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGjpY1r2mlvK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2yGaegnmlWh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "LSTMwithFullEmbeddingandPOS",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
