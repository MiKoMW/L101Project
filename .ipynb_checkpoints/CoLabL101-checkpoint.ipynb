{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NYQAJyGZ5-Eu",
    "outputId": "d580219f-97e6-4b37-9d96-a29547a88ef0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xmnlp\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/62/bee2665a3f757f0e8b918ba8610e389f6e25392489dbd889b5ed9addc0ca/xmnlp-0.2.3.tar.gz (23.7MB)\n",
      "\u001b[K     |████████████████████████████████| 23.7MB 1.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.6/dist-packages (from xmnlp) (1.19.4)\n",
      "Building wheels for collected packages: xmnlp\n",
      "  Building wheel for xmnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for xmnlp: filename=xmnlp-0.2.3-cp36-none-any.whl size=23707964 sha256=9ec96a6373fb56bb00a8c98d121a449561771c420ce6577aea33e46fbe547beb\n",
      "  Stored in directory: /root/.cache/pip/wheels/1d/05/70/4a9b15884cdd6997fbc006fd6a9c2b3f5ca66857b6ac37100c\n",
      "Successfully built xmnlp\n",
      "Installing collected packages: xmnlp\n",
      "Successfully installed xmnlp-0.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install xmnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "447bQ9Ar7EfP",
    "outputId": "2cb01bff-cc92-4ce8-edb6-93cbcfabfe0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "m0VD2Zcb58TO"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "import collections\n",
    "import operator\n",
    "from functools import reduce\n",
    "import json\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YB7q5lpT58Ta",
    "outputId": "e0bfcd6e-bd09-426a-c63c-477fc61991dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Lazy Load) Loading model...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['艹', '丿', '日', '王']"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xmnlp\n",
    "xmnlp.radical('花丸晴琉')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "x6gF-5xO58Tc"
   },
   "outputs": [],
   "source": [
    "# Build up Chinese sub-character unites diactionary.\n",
    "chaiZi_Dic = {}\n",
    "\n",
    "googlePath = \"./drive/MyDrive/L101Project/\"\n",
    "# googlePath = \"./\"\n",
    "with open(googlePath + \"corpus/chaizi/chaizi-jt.txt\", 'r') as f:\n",
    "    reader = csv.reader(f,delimiter='\\t')\n",
    "    for row in reader:\n",
    "        chaiZi_Dic[row[0]] = row[1]\n",
    "        \n",
    "def getSubChar(charCN):\n",
    "    if(charCN in chaiZi_Dic.keys()):\n",
    "        return chaiZi_Dic[item]\n",
    "    else:\n",
    "        return [None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OrIE3_0b58Td",
    "outputId": "43612090-a25e-4c4d-916d-ae3c42f23c19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14563\n",
      "草 化\n",
      "['艹']\n",
      "\n",
      "丶 九\n",
      "['丿']\n",
      "\n",
      "[None]\n",
      "[None]\n",
      "\n",
      "日 青\n",
      "['日']\n",
      "\n",
      "玉 亠 厶 川\n",
      "['王']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(chaiZi_Dic.keys()))\n",
    "for item in \"花丸A晴琉\":\n",
    "    print(getSubChar(item))\n",
    "    print(xmnlp.radical(item))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4v2Pc80y6JQa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "tYdRVuau58Te"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GES71xxQ58Tf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "c8HAOyQG58Tf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "mJJZT1Y_58Tg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hKVGjNWi58Th"
   },
   "outputs": [],
   "source": [
    "## Create Corpus for Chinese Word Segamentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "ytbm5qmw58Th",
    "outputId": "e7a4bfdb-4694-45c3-de57-b82e43a8679e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>迈向  充满  希望  的  新  世纪  ——  一九九八年  新年  讲话  （  附 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input\n",
       "0  迈向  充满  希望  的  新  世纪  ——  一九九八年  新年  讲话  （  附 ..."
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pkuTrain = googlePath + \"./corpus/cws/icwb2-data/training/pku_training.utf8\"\n",
    "pkuTest = googlePath + \"./corpus/cws/icwb2-data/testing/pku_test.utf8\"\n",
    "train = pd.read_table(pkuTrain,  encoding='utf8', header=None, names=['input'])  # don't drop the empty lines yet, they show up as NaN in the data frame\n",
    "train.head(n=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "k0_kbgIF58Tj",
    "outputId": "991c401f-d4c8-4743-ac38-b4cf6ca08c84"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>raws</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>共同创造美好的新世纪——二○○一年新年贺词</td>\n",
       "      <td>共同创造美好的新世纪——二○○一年新年贺词</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   input                   raws\n",
       "0  共同创造美好的新世纪——二○○一年新年贺词  共同创造美好的新世纪——二○○一年新年贺词"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkuTest = googlePath  + \"./corpus/cws/icwb2-data/testing/pku_test.utf8\"\n",
    "test = pd.read_table(pkuTest,  encoding='utf8', header=None, names=['input']) \n",
    "test[\"raws\"] = test[\"input\"]\n",
    "test.head(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A65VnpGQ58Tk",
    "outputId": "ba154d54-1cdc-4c45-81c8-82b150cc0ec9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19054\n"
     ]
    }
   ],
   "source": [
    "def prepross_data(train_Data):\n",
    "    inputs = train_Data[\"input\"][:]\n",
    "    print(len(inputs))\n",
    "    raws = []\n",
    "    tokenList = []\n",
    "    \n",
    "    for item in inputs:\n",
    "        item = item.replace(\"   \", \"  \")\n",
    "\n",
    "        raw = item.replace(\" \", \"\")\n",
    "#         print(item)\n",
    "#         print(raw)\n",
    "        raws.append(raw)\n",
    "        tokens = (item.split(\"  \")[:-1])\n",
    "        tokenList.append(tokens)\n",
    "#         print(tokens)\n",
    "    train_Data[\"raws\"] = raws\n",
    "    train_Data[\"tokenList\"] = tokenList\n",
    "    dictionary_train_word = list(set(reduce(operator.add,train_Data[\"tokenList\"])))\n",
    "    dictionary_train_char =  list(set(reduce(operator.add,train_Data[\"raws\"])))    \n",
    "    return train_Data, dictionary_train_char, dictionary_train_word\n",
    "train, train_dic_char, train_dic_word  = prepross_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "oTEBdHbG58Tl"
   },
   "outputs": [],
   "source": [
    "# Validate the pre-processing\n",
    "def validate_data(data):\n",
    "    tkList = data[\"tokenList\"]\n",
    "    raws = data[\"raws\"]\n",
    "    for (tokens, raw) in zip(tkList,raws):\n",
    "#         print(tokens)\n",
    "        \n",
    "#         print(raw)\n",
    "        temp  = \"\".join(tokens)\n",
    "#         print(temp)\n",
    "        assert(temp == raw)\n",
    "        if not (temp == raw):\n",
    "            print(temp)\n",
    "            print(raw)\n",
    "            print(tokens)\n",
    "validate_data(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "uXAYiepL58Tl",
    "outputId": "3237d7aa-18e8-4cbd-de3e-8d9b8e70c901"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>raws</th>\n",
       "      <th>tokenList</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>迈向  充满  希望  的  新  世纪  ——  一九九八年  新年  讲话  （  附 ...</td>\n",
       "      <td>迈向充满希望的新世纪——一九九八年新年讲话（附图片１张）</td>\n",
       "      <td>[迈向, 充满, 希望, 的, 新, 世纪, ——, 一九九八年, 新年, 讲话, （, 附...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>中共中央  总书记  、  国家  主席  江  泽民</td>\n",
       "      <td>中共中央总书记、国家主席江泽民</td>\n",
       "      <td>[中共中央, 总书记, 、, 国家, 主席, 江, 泽民]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>（  一九九七年  十二月  三十一日  ）</td>\n",
       "      <td>（一九九七年十二月三十一日）</td>\n",
       "      <td>[（, 一九九七年, 十二月, 三十一日, ）]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>１２月  ３１日  ，  中共中央  总书记  、  国家  主席  江  泽民  发表  ...</td>\n",
       "      <td>１２月３１日，中共中央总书记、国家主席江泽民发表１９９８年新年讲话《迈向充满希望的新世纪》。...</td>\n",
       "      <td>[１２月, ３１日, ，, 中共中央, 总书记, 、, 国家, 主席, 江, 泽民, 发表,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>同胞  们  、  朋友  们  、  女士  们  、  先生  们  ：</td>\n",
       "      <td>同胞们、朋友们、女士们、先生们：</td>\n",
       "      <td>[同胞, 们, 、, 朋友, 们, 、, 女士, 们, 、, 先生, 们, ：]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  ...                                          tokenList\n",
       "0  迈向  充满  希望  的  新  世纪  ——  一九九八年  新年  讲话  （  附 ...  ...  [迈向, 充满, 希望, 的, 新, 世纪, ——, 一九九八年, 新年, 讲话, （, 附...\n",
       "1                      中共中央  总书记  、  国家  主席  江  泽民    ...                      [中共中央, 总书记, 、, 国家, 主席, 江, 泽民]\n",
       "2                           （  一九九七年  十二月  三十一日  ）    ...                           [（, 一九九七年, 十二月, 三十一日, ）]\n",
       "3  １２月  ３１日  ，  中共中央  总书记  、  国家  主席  江  泽民  发表  ...  ...  [１２月, ３１日, ，, 中共中央, 总书记, 、, 国家, 主席, 江, 泽民, 发表,...\n",
       "4           同胞  们  、  朋友  们  、  女士  们  、  先生  们  ：    ...           [同胞, 们, 、, 朋友, 们, 、, 女士, 们, 、, 先生, 们, ：]\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GA1TnYl-58Tm",
    "outputId": "5527b84c-48f3-4ac5-bcc0-ed84287826de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4698\n",
      "4698\n",
      "55303\n",
      "55303\n",
      "55303\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dic_char))\n",
    "print(len(set(train_dic_char)))\n",
    "print(len(train_dic_word))\n",
    "print(len(set(train_dic_word)))\n",
    "with open(googlePath + \"./corpus/cws/icwb2-data/gold/pku_training_words.utf8\", 'r') as f:\n",
    "    content = f.readlines()  \n",
    "    print(len(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "KtzTiApG58Tn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QhhdX_Pl58Tn",
    "outputId": "56f3fd95-e287-41bc-b42f-86d620f49577"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4698\n"
     ]
    }
   ],
   "source": [
    "# Feature extraction\n",
    "\n",
    "oov = len(train_dic_char)\n",
    "print(oov)\n",
    "def token_index(tok):\n",
    "    ind = tok\n",
    "    if tok in train_dic_char:  # if token in vocabulary\n",
    "        ind = train_dic_char.index(tok)\n",
    "    else:  # else it's OOV\n",
    "        ind = oov\n",
    "    return ind\n",
    "\n",
    "def str_token_index(string):\n",
    "    return [token_index(x)   for x in string]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# training labels: convert BIO to integers\n",
    "# def bio_index(bio):\n",
    "#     ind = bio\n",
    "#     if not pd.isnull(bio):  # deal with empty lines\n",
    "#         if bio=='B':\n",
    "#             ind = 0\n",
    "#         elif bio=='I':\n",
    "#             ind = 1\n",
    "#         elif bio=='O':\n",
    "#             ind = 2\n",
    "#     return ind\n",
    "\n",
    "# Get Begin Middle End Single sequence\n",
    "# B 0 M 1 E 2 S 3\n",
    "\n",
    "def str_bmes_idx(tokenList):\n",
    "    answer = []\n",
    "    for item in tokenList:\n",
    "        if len(item) == 0:\n",
    "            raise NameErro(\"Zero Length Word\")\n",
    "        if len(item) == 1:\n",
    "            answer.append(3)\n",
    "        else:\n",
    "            answer.append(0)\n",
    "            for item in range(len(item) - 2):\n",
    "                answer.append(1)\n",
    "            answer.append(2)\n",
    "    return answer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_features(data_set, isTest=False):\n",
    "    data_temp = data_set.copy()\n",
    "    \n",
    "\n",
    "    # Idx for chars\n",
    "    with Pool(8) as p:\n",
    "        tokinds = p.map(str_token_index,data_temp['raws'])\n",
    "#     tokinds = [list(map(token_index, u)) for u in data_temp['raws']]\n",
    "    data_temp[\"tokenIdx\"] = tokinds\n",
    "    \n",
    "    # BIO\n",
    "    if(not isTest):\n",
    "        data_temp[\"bmes\"] = [str_bmes_idx(u) for u in data_temp['tokenList']]\n",
    "        assert (list(map(len,data_temp[\"bmes\"])) == list(map(len,data_temp[\"tokenIdx\"])))\n",
    "\n",
    "        \n",
    "#     print(data_temp[\"bmes\"])\n",
    "#    assert reduce(operator.and_, list(map(len,data_temp[\"bmes\"])) == list(map(len,data_temp[\"tokenIdx\"])))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return data_temp\n",
    "#     txt['token_indices'] = tokinds\n",
    "#     if not istest:  # can't do this with the test set\n",
    "#         bioints = [bio_index(b) for b in txt['bio_only']]\n",
    "#         txt['bio_only'] = bioints\n",
    "#     return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9w4lo1yb58To",
    "outputId": "e79d1020-ec35-4f80-ce57-9e7425ba7c28",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 870 ms, sys: 149 ms, total: 1.02 s\n",
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# MultiThreading\n",
    "temp = extract_features(train)\n",
    "train_feature = temp\n",
    "train_feature.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "wh8zL8EK58Tp"
   },
   "outputs": [],
   "source": [
    "def find_longest_sequence(data_with_features):\n",
    "#     assert (np.max(list(map(len, data_with_features[\"tokenIdx\"])))) == (np.max(list(map(len, data_with_features[\"bmes\"]))))\n",
    "    return (np.max(list(map(len, data_with_features[\"tokenIdx\"]))))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4YzaOcT058Tp",
    "outputId": "de26717b-bfcf-4f16-dc95-0f473c29bfb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.5 ms, sys: 65.1 ms, total: 98.6 ms\n",
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "temp = extract_features(test, isTest=True)\n",
    "test_feature = temp\n",
    "test_feature.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T1Z43yCI58Tq",
    "outputId": "5d45132f-c8be-4041-fb75-0cef1d0150dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1019\n",
      "626\n",
      "1019\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_longest = find_longest_sequence(train_feature)\n",
    "print(train_longest)\n",
    "\n",
    "test_longest = find_longest_sequence(test_feature)\n",
    "print(test_longest)\n",
    "\n",
    "seq_longest = np.max([train_longest,test_longest])\n",
    "print(seq_longest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O_iHq0oB58Tr",
    "outputId": "4ecb1dfd-798f-4e9b-88e9-0d83e3ae3788",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The padding token index is 4699\n",
      "Example of padded token sequence:\n",
      "[4063  466 4063 ... 4699 4699 4699]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "seq_length = seq_longest\n",
    "\n",
    "# a new dummy token index, one more than OOV\n",
    "padtok = oov+1\n",
    "print('The padding token index is %i' % padtok)\n",
    "\n",
    "# use pad_sequences, padding or truncating at the end of the sequence (default is 'pre')\n",
    "train_seqs_padded = pad_sequences(train_feature['tokenIdx'].tolist(), maxlen=seq_length,\n",
    "                                  dtype='int32', padding='post', truncating='post', value=padtok)\n",
    "print('Example of padded token sequence:')\n",
    "print(train_seqs_padded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eKbwZstn58Ts",
    "outputId": "d80d35d5-6d83-458e-bd25-5d3c2567dcb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of input sequence: 1019\n",
      "Length of label sequence: 1019\n",
      "[0 1 1 2 0 1 2 3 0 2 0]\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# get lists of named entity labels, padded with a null label (=3)\n",
    "padlab = 4\n",
    "train_labs_padded = pad_sequences(train_feature['bmes'].tolist(), maxlen=seq_length,\n",
    "                                  dtype='int32', padding='post', truncating='post', value=padlab)\n",
    "\n",
    "# convert those labels to one-hot encoding\n",
    "n_labs = 5\n",
    "train_labs_onehot = [to_categorical(i, num_classes=n_labs) for i in train_labs_padded]\n",
    "\n",
    "# follow the print outputs below to see how the labels are transformed\n",
    "print('Length of input sequence: %i' % len(train_labs_padded[1]))\n",
    "print('Length of label sequence: %i' % len(train_labs_onehot[1]))\n",
    "print(train_labs_padded[1][:11])\n",
    "print(train_labs_onehot[1][:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "apIdlQs858Tt",
    "outputId": "f2c92c15-c349-491d-fce7-4c74c943174d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence dimensions (n.docs, seq.length):\n",
      "(19054, 1019)\n",
      "Label dimensions (n.docs, seq.length, one-hot encoding of 4 NER labels):\n",
      "(19054, 1019, 5)\n",
      "True\n",
      "**Defining a neural network**\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 1019, 128)         601600    \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 1019, 100)         71600     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1019, 100)         0         \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 1019, 5)           505       \n",
      "=================================================================\n",
      "Total params: 673,705\n",
      "Trainable params: 673,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load Keras and TensorFlow\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# prepare sequences and labels as numpy arrays, check dimensions\n",
    "X = np.array(train_seqs_padded)\n",
    "y = np.array(train_labs_onehot)\n",
    "print('Input sequence dimensions (n.docs, seq.length):')\n",
    "print(X.shape)\n",
    "print('Label dimensions (n.docs, seq.length, one-hot encoding of 4 NER labels):')\n",
    "print(y.shape)\n",
    "\n",
    "# our final vocab size is the padding token + 1 (OR length of vocab + OOV + PAD)\n",
    "vocab_size = padtok+1\n",
    "print(vocab_size==len(train_dic_char)+2)\n",
    "embed_size = 128  # try an embedding size of 128 (could tune this)\n",
    "\n",
    "# list of metrics to use: true & false positives, negatives, accuracy, precision, recall, area under the curve\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "\n",
    "# our model has the option for an label prediction bias, it's sequential, starts with an embedding layer, then bi-LSTM,\n",
    "# a dropout layer follows for regularisation, and a dense final layer with softmax activation to output class probabilities\n",
    "# we compile with the Adam optimizer at a low learning rate, use categorical cross-entropy as our loss function\n",
    "def make_model(metrics = METRICS, output_bias=None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Embedding(input_dim=vocab_size, output_dim=embed_size, input_length=seq_length, mask_zero=True, trainable=True),\n",
    "        keras.layers.Bidirectional(keras.layers.LSTM(units=50, return_sequences=True, dropout=0.2)),  # 2 directions, 50 units each, concatenated (can change this)\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.TimeDistributed(keras.layers.Dense(n_labs, activation='softmax', bias_initializer=output_bias)),\n",
    "    ])\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=1e-3), loss=keras.losses.CategoricalCrossentropy(), metrics=metrics)\n",
    "    return model\n",
    "\n",
    "# early stopping criteria based on area under the curve: will stop if no improvement after 10 epochs\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_auc', verbose=1, patience=10, mode='max', restore_best_weights=True)\n",
    "\n",
    "# the number of training epochs we'll use, and the batch size (how many texts are input at once)\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "print('**Defining a neural network**')\n",
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ld9ThJPw58Tv",
    "outputId": "e2123fd9-518f-422a-8dc7-b3dcb6c8ed6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.10270172, 0.15502793, 0.10697573, 0.3753263 , 0.25996837],\n",
       "        [0.10112179, 0.1567188 , 0.10722968, 0.3762475 , 0.25868216],\n",
       "        [0.10277834, 0.15696697, 0.10800291, 0.3748632 , 0.25738853],\n",
       "        ...,\n",
       "        [0.10478016, 0.15736046, 0.1039803 , 0.3750086 , 0.25887054],\n",
       "        [0.10473602, 0.15725306, 0.1040602 , 0.37440372, 0.25954702],\n",
       "        [0.10474363, 0.15706088, 0.10416794, 0.3738505 , 0.26017708]],\n",
       "\n",
       "       [[0.10347926, 0.15324576, 0.1052032 , 0.38117042, 0.2569013 ],\n",
       "        [0.10502847, 0.15341236, 0.1057971 , 0.37981907, 0.25594297],\n",
       "        [0.10438517, 0.15390283, 0.10470287, 0.3821454 , 0.25486365],\n",
       "        ...,\n",
       "        [0.10478016, 0.15736046, 0.1039803 , 0.3750086 , 0.25887054],\n",
       "        [0.10473603, 0.15725306, 0.1040602 , 0.37440372, 0.25954702],\n",
       "        [0.10474363, 0.15706088, 0.10416794, 0.3738505 , 0.26017708]],\n",
       "\n",
       "       [[0.10514718, 0.15634522, 0.10740366, 0.3712803 , 0.2598236 ],\n",
       "        [0.10383039, 0.15468517, 0.10635542, 0.37662157, 0.2585074 ],\n",
       "        [0.10288596, 0.1517151 , 0.10701066, 0.37579072, 0.26259753],\n",
       "        ...,\n",
       "        [0.10478016, 0.15736046, 0.1039803 , 0.3750086 , 0.25887054],\n",
       "        [0.10473602, 0.15725306, 0.1040602 , 0.37440372, 0.25954702],\n",
       "        [0.10474363, 0.15706088, 0.10416794, 0.3738505 , 0.26017708]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.10260335, 0.15068626, 0.10358   , 0.38186598, 0.26126438],\n",
       "        [0.10449851, 0.15316254, 0.10407391, 0.38186163, 0.25640345],\n",
       "        [0.10466512, 0.15258682, 0.10434455, 0.38494986, 0.2534537 ],\n",
       "        ...,\n",
       "        [0.10478016, 0.15736046, 0.1039803 , 0.3750086 , 0.25887054],\n",
       "        [0.10473603, 0.15725306, 0.1040602 , 0.37440372, 0.25954702],\n",
       "        [0.10474363, 0.15706088, 0.10416794, 0.3738505 , 0.26017708]],\n",
       "\n",
       "       [[0.10308328, 0.15102537, 0.1038387 , 0.38114718, 0.26090544],\n",
       "        [0.10506605, 0.15353377, 0.1043565 , 0.38106158, 0.25598207],\n",
       "        [0.1053268 , 0.15298992, 0.10465289, 0.3840542 , 0.2529762 ],\n",
       "        ...,\n",
       "        [0.10478016, 0.15736046, 0.1039803 , 0.3750086 , 0.25887054],\n",
       "        [0.10473603, 0.15725306, 0.1040602 , 0.37440372, 0.25954702],\n",
       "        [0.10474363, 0.15706088, 0.10416794, 0.3738505 , 0.26017708]],\n",
       "\n",
       "       [[0.1007686 , 0.15133421, 0.10656801, 0.3793303 , 0.26199892],\n",
       "        [0.10035115, 0.15379693, 0.1082634 , 0.37554282, 0.2620457 ],\n",
       "        [0.10097715, 0.15498824, 0.10775275, 0.37257904, 0.26370287],\n",
       "        ...,\n",
       "        [0.10478016, 0.15736046, 0.1039803 , 0.3750086 , 0.25887054],\n",
       "        [0.10473603, 0.15725306, 0.1040602 , 0.37440372, 0.25954702],\n",
       "        [0.10474363, 0.15706088, 0.10416794, 0.3738505 , 0.26017708]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kq6Yhs9E58Tw",
    "outputId": "d3394c46-206a-4a8b-a501-e056ff4a33df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.1268\n",
      "CPU times: user 16min 32s, sys: 21.3 s, total: 16min 54s\n",
      "Wall time: 8min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# evaluate our initial model\n",
    "results = model.evaluate(X, y, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0M6Q1rQg58Tw",
    "outputId": "b19133d5-f8e9-4d11-9ffd-15d8e5dd6475"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({4: 17589578, 0: 585226, 2: 585226, 3: 524721, 1: 131275})\n",
      "19416026\n",
      "Initial bias:\n",
      "[0.03014138938627297, 0.006761167295511451, 0.03014138938627297, 0.027025149224666263, 0.9059309047072763]\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Loss: 1.1097\n"
     ]
    }
   ],
   "source": [
    "# figure out the label distribution in our fixed-length texts\n",
    "from collections import Counter\n",
    "\n",
    "all_labs = [l for lab in train_labs_padded for l in lab]\n",
    "label_count = Counter(all_labs)\n",
    "total_labs = len(all_labs)\n",
    "print(label_count)\n",
    "print(total_labs)\n",
    "\n",
    "# use this to define an initial model bias\n",
    "initial_bias=[(label_count[0]/total_labs), (label_count[1]/total_labs),\n",
    "              (label_count[2]/total_labs), (label_count[3]/total_labs), (label_count[4]/total_labs)]\n",
    "print('Initial bias:')\n",
    "print(initial_bias)\n",
    "\n",
    "# pass the bias to the model and re-evaluate\n",
    "model = make_model(output_bias=initial_bias)\n",
    "results = model.evaluate(X, y, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t_nVby7eK3uL",
    "outputId": "6de131b5-c1c0-4273-b30b-bb65949e462b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4266156043005113568\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 14638920512\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12003566870847733514\n",
      "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w-Cp9ce8LSag",
    "outputId": "46cbffea-ebb9-437b-a29e-2e3606c47655"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "45sWeuEu58Tx",
    "outputId": "5d5a2189-014e-4871-894f-d849f92735db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "105/105 [==============================] - 162s 1s/step - loss: 0.4297 - tp: 5519757.2830 - fp: 50700.1226 - tn: 27848822.9623 - fn: 1455123.5189 - accuracy: 0.9364 - precision: 0.9432 - recall: 0.6892 - auc: 0.9857 - val_loss: 0.1189 - val_tp: 5292816.0000 - val_fp: 1992.0000 - val_tn: 23300460.0000 - val_fn: 532797.0000 - val_accuracy: 0.9816 - val_precision: 0.9996 - val_recall: 0.9085 - val_auc: 0.9982\n",
      "Epoch 2/50\n",
      "105/105 [==============================] - 131s 1s/step - loss: 0.1205 - tp: 6347995.6698 - fp: 15962.3208 - tn: 27883562.7453 - fn: 626886.0943 - accuracy: 0.9813 - precision: 0.9981 - recall: 0.9081 - auc: 0.9980 - val_loss: 0.0817 - val_tp: 5529031.0000 - val_fp: 48361.0000 - val_tn: 23254090.0000 - val_fn: 296582.0000 - val_accuracy: 0.9882 - val_precision: 0.9913 - val_recall: 0.9491 - val_auc: 0.9992\n",
      "Epoch 3/50\n",
      "105/105 [==============================] - 136s 1s/step - loss: 0.0815 - tp: 6677975.2830 - fp: 102243.7170 - tn: 27797298.2547 - fn: 296910.3679 - accuracy: 0.9880 - precision: 0.9850 - recall: 0.9545 - auc: 0.9992 - val_loss: 0.0521 - val_tp: 5686039.0000 - val_fp: 70162.0000 - val_tn: 23232284.0000 - val_fn: 139574.0000 - val_accuracy: 0.9928 - val_precision: 0.9878 - val_recall: 0.9760 - val_auc: 0.9997\n",
      "Epoch 4/50\n",
      "105/105 [==============================] - 139s 1s/step - loss: 0.0548 - tp: 6806365.0000 - fp: 90075.1415 - tn: 27809459.8019 - fn: 168518.4434 - accuracy: 0.9924 - precision: 0.9868 - recall: 0.9752 - auc: 0.9996 - val_loss: 0.0422 - val_tp: 5716858.0000 - val_fp: 63605.0000 - val_tn: 23238848.0000 - val_fn: 108755.0000 - val_accuracy: 0.9941 - val_precision: 0.9890 - val_recall: 0.9813 - val_auc: 0.9997\n",
      "Epoch 5/50\n",
      "105/105 [==============================] - 148s 1s/step - loss: 0.0457 - tp: 6836445.7170 - fp: 82364.2358 - tn: 27817164.7736 - fn: 138437.0943 - accuracy: 0.9937 - precision: 0.9881 - recall: 0.9801 - auc: 0.9996 - val_loss: 0.0396 - val_tp: 5725343.0000 - val_fp: 61484.0000 - val_tn: 23240966.0000 - val_fn: 100270.0000 - val_accuracy: 0.9944 - val_precision: 0.9894 - val_recall: 0.9828 - val_auc: 0.9998\n",
      "Epoch 6/50\n",
      "105/105 [==============================] - 143s 1s/step - loss: 0.0433 - tp: 6845762.3019 - fp: 79589.5849 - tn: 27819947.5377 - fn: 129122.6321 - accuracy: 0.9940 - precision: 0.9885 - recall: 0.9813 - auc: 0.9997 - val_loss: 0.0381 - val_tp: 5731153.0000 - val_fp: 61130.0000 - val_tn: 23241328.0000 - val_fn: 94460.0000 - val_accuracy: 0.9947 - val_precision: 0.9894 - val_recall: 0.9838 - val_auc: 0.9998\n",
      "Epoch 7/50\n",
      "105/105 [==============================] - 130s 1s/step - loss: 0.0411 - tp: 6853734.6509 - fp: 77091.3019 - tn: 27822441.7170 - fn: 121147.5849 - accuracy: 0.9943 - precision: 0.9888 - recall: 0.9825 - auc: 0.9997 - val_loss: 0.0369 - val_tp: 5735493.0000 - val_fp: 60314.0000 - val_tn: 23242136.0000 - val_fn: 90120.0000 - val_accuracy: 0.9948 - val_precision: 0.9896 - val_recall: 0.9845 - val_auc: 0.9998\n",
      "Epoch 8/50\n",
      "105/105 [==============================] - 143s 1s/step - loss: 0.0393 - tp: 6859973.1698 - fp: 74676.7264 - tn: 27824863.5849 - fn: 114912.0283 - accuracy: 0.9945 - precision: 0.9892 - recall: 0.9835 - auc: 0.9997 - val_loss: 0.0357 - val_tp: 5739317.0000 - val_fp: 59009.0000 - val_tn: 23243444.0000 - val_fn: 86296.0000 - val_accuracy: 0.9950 - val_precision: 0.9898 - val_recall: 0.9852 - val_auc: 0.9998\n",
      "Epoch 9/50\n",
      "105/105 [==============================] - 138s 1s/step - loss: 0.0370 - tp: 6866322.9906 - fp: 71752.4057 - tn: 27827779.6887 - fn: 108560.2736 - accuracy: 0.9949 - precision: 0.9898 - recall: 0.9846 - auc: 0.9997 - val_loss: 0.0345 - val_tp: 5743367.0000 - val_fp: 57541.0000 - val_tn: 23244912.0000 - val_fn: 82246.0000 - val_accuracy: 0.9952 - val_precision: 0.9901 - val_recall: 0.9859 - val_auc: 0.9997\n",
      "Epoch 10/50\n",
      "105/105 [==============================] - 127s 1s/step - loss: 0.0360 - tp: 6871239.9906 - fp: 69963.1132 - tn: 27829578.0566 - fn: 103644.4245 - accuracy: 0.9950 - precision: 0.9900 - recall: 0.9851 - auc: 0.9997 - val_loss: 0.0334 - val_tp: 5746821.0000 - val_fp: 55900.0000 - val_tn: 23246544.0000 - val_fn: 78792.0000 - val_accuracy: 0.9954 - val_precision: 0.9904 - val_recall: 0.9865 - val_auc: 0.9998\n",
      "Epoch 11/50\n",
      "105/105 [==============================] - 139s 1s/step - loss: 0.0346 - tp: 6875483.3302 - fp: 68291.7358 - tn: 27831258.8679 - fn: 99404.3491 - accuracy: 0.9952 - precision: 0.9902 - recall: 0.9858 - auc: 0.9997 - val_loss: 0.0325 - val_tp: 5749890.0000 - val_fp: 55120.0000 - val_tn: 23247328.0000 - val_fn: 75723.0000 - val_accuracy: 0.9955 - val_precision: 0.9905 - val_recall: 0.9870 - val_auc: 0.9997\n",
      "Epoch 12/50\n",
      "105/105 [==============================] - 139s 1s/step - loss: 0.0336 - tp: 6879888.6321 - fp: 66145.6415 - tn: 27833387.5849 - fn: 94995.5283 - accuracy: 0.9954 - precision: 0.9905 - recall: 0.9863 - auc: 0.9997 - val_loss: 0.0317 - val_tp: 5752197.0000 - val_fp: 53846.0000 - val_tn: 23248604.0000 - val_fn: 73416.0000 - val_accuracy: 0.9956 - val_precision: 0.9907 - val_recall: 0.9874 - val_auc: 0.9997\n",
      "Epoch 13/50\n",
      "105/105 [==============================] - 131s 1s/step - loss: 0.0326 - tp: 6882797.2453 - fp: 64838.1509 - tn: 27834702.6415 - fn: 92088.3679 - accuracy: 0.9955 - precision: 0.9907 - recall: 0.9868 - auc: 0.9997 - val_loss: 0.0310 - val_tp: 5754443.0000 - val_fp: 53101.0000 - val_tn: 23249348.0000 - val_fn: 71170.0000 - val_accuracy: 0.9957 - val_precision: 0.9909 - val_recall: 0.9878 - val_auc: 0.9997\n",
      "Epoch 14/50\n",
      "105/105 [==============================] - 135s 1s/step - loss: 0.0316 - tp: 6886264.8491 - fp: 63228.6038 - tn: 27836298.3208 - fn: 88617.5566 - accuracy: 0.9956 - precision: 0.9909 - recall: 0.9873 - auc: 0.9997 - val_loss: 0.0303 - val_tp: 5756333.0000 - val_fp: 51980.0000 - val_tn: 23250470.0000 - val_fn: 69280.0000 - val_accuracy: 0.9958 - val_precision: 0.9911 - val_recall: 0.9881 - val_auc: 0.9997\n",
      "Epoch 15/50\n",
      "105/105 [==============================] - 136s 1s/step - loss: 0.0307 - tp: 6889075.5472 - fp: 61740.6604 - tn: 27837802.6981 - fn: 85810.0755 - accuracy: 0.9958 - precision: 0.9912 - recall: 0.9877 - auc: 0.9997 - val_loss: 0.0297 - val_tp: 5758038.0000 - val_fp: 51187.0000 - val_tn: 23251264.0000 - val_fn: 67575.0000 - val_accuracy: 0.9959 - val_precision: 0.9912 - val_recall: 0.9884 - val_auc: 0.9997\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9bf385a160>"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-initiate model with bias\n",
    "model = make_model(output_bias=initial_bias)\n",
    "\n",
    "# and fit...\n",
    "model.fit(X, y, batch_size=BATCH_SIZE, epochs=50, callbacks = [early_stopping],  validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fSs6aH1T58Ty",
    "outputId": "d42a1897-46cf-4ca6-a695-87ed3086563e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12684282398299221539\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NX_hvCrE58Ty",
    "outputId": "77f2ab09-27c6-4e50-a53f-82c44fbf4750"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FaNLQxzj58Tz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "L101.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
